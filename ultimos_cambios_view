import streamlit as st
import time
import base64
import pathlib
from pathlib import Path
import pandas as pd
import numpy as np
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.metrics import silhouette_score
from scipy.cluster.hierarchy import linkage
from statsmodels.formula.api import ols
import statsmodels.api as sm
from statsmodels.stats.multicomp import pairwise_tukeyhsd
import plotly.express as px
import plotly.graph_objects as go
import plotly.figure_factory as ff
import seaborn as sns
from models import (
    DatasetModel,
    PreprocessingModel,
    PCAModel,
    ClusteringModel,
    ANOVAModel,
)
from services import AIService


def home_page():
    st.title("QuimioAnalytics")

    # Define the text for the speech bubble (Using Spanish greeting from your source)
    ASSISTANT_GREETING = "Hola, mi nombre es Heisenberg y soy tu assistente virtual. Carga tu dataset y puedo ayudarte üôÇ"

    # ---------- Read local image and convert to base64 ----------
    # NOTE: This part assumes 'man.png' exists in the same directory where the script is run.
    img_path = pathlib.Path("man.png")
    img_data_uri = None
    try:
        with img_path.open("rb") as f:
            data = f.read()
            b64 = base64.b64encode(data).decode("utf-8")
            img_data_uri = f"data:image/png;base64,{b64}"
    except Exception as e:
        # If reading fails, fall back to a simple st.image (so user still sees something)
        st.warning(
            f"Could not embed man.png as data URI ({e}). Falling back to st.image below."
        )

    # ---------- CSS for positioning the floating image AND the speech bubble ----------
    # The image is now just a static floating element.
    st.markdown(
        f"""
    <style>
    /* ensures the floating image sits above other content and doesn't affect layout */
    .floating-image-container {{
        position: fixed;
        top: 250px;      /* Vertical position */
        right: 18px;    /* distance from right edge */
        width: 160px;   /* max width of the container */
        z-index: 9999;
        text-align: center;
        /* cursor: pointer; -- REMOVED */
    }}
    
    /* Ensure the link wrapper takes up the whole container area and removes link styles */
    /* .floating-link is no longer used, CSS kept for robustness */
    .floating-link {{
        display: block;
        color: inherit;
        text-decoration: none;
    }}

    .floating-image-container img {{
        width: 100%;
        height: auto;
        border-radius: 0px;
        box-shadow: 0 0px 0px rgba(0,0,0,0);
        display: block;
        margin: 0;
    }}

    /* Speech Bubble Styles */
    .speech-bubble {{
        background: #eef4ff; /* Light blue/grey for a modern look */
        color: #333333;
        padding: 10px 15px;
        border-radius: 15px;
        margin-bottom: 8px; /* Space between bubble and image */
        position: relative;
        font-size: 13px; /* Slightly smaller text for the bubble */
        text-align: left;
        box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        line-height: 1.4;
    }}

    /* Speech bubble tail (points down to the image) */
    .speech-bubble::after {{
        content: '';
        position: absolute;
        bottom: -10px; /* Position below the bubble */
        left: 50%;
        transform: translateX(-50%);
        width: 0;
        height: 0;
        border-left: 10px solid transparent;
        border-right: 10px solid transparent;
        border-top: 10px solid #eef4ff; /* Match bubble background color */
    }}

    /* Add a subtle hover effect to indicate clickability */
    .floating-image-container:hover {{
        /* REMOVED hover effect */
        /* transition: transform 0.2s ease-in-out; */
    }}
    </style>
    """,
        unsafe_allow_html=True,
    )

    # ---------- WELCOME CARD (unchanged from your source) ----------
    st.markdown(
        """
    <div style='
        background-color: #ffffff;
        padding: 30px;
        border-radius: 15px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        text-align: center;
        max-width: 650px;
        margin-left: auto;
        margin-right: auto;
    '>
        <h2 style='margin-bottom: 10px;'>Bienvenido a QuimioAnalytics</h2>
        <p style='font-size: 16px; color: #444;'>
            Esta plataforma est√° dise√±ada especialmente para <strong>estudiantes de qu√≠mica</strong> 
            que desean explorar y analizar datos de manera intuitiva, sin necesidad de programar.
        </p>
        <p style='font-size: 1rem; color: #666; margin-top: 20px;'>
            Utiliza el panel lateral para navegar entre las diferentes herramientas de an√°lisis.
        </p>
    </div>
    """,
        unsafe_allow_html=True,
    )

    # ---------- Insert floating image (data URI) or fallback (STATIC) ----------
    if img_data_uri:
        # RENDERED WITHOUT THE <a> TAG WRAPPER
        html = f"""
            <div class="floating-image-container">
                <div class="speech-bubble">
                    {ASSISTANT_GREETING}
                </div>
                <img src="{img_data_uri}" alt="Heisenberg">
            </div>
        """
        st.markdown(html, unsafe_allow_html=True)
    else:
        # fallback: use st.image (will occupy a normal Streamlit spot but only shown if embedding failed)
        st.image("man.png", caption=ASSISTANT_GREETING, width=140)

    st.markdown("---")

    # Tabs for organization
    tab1, tab2, tab3 = st.tabs(
        ["Introducci√≥n", "Fundamentos Te√≥ricos", "Ejemplo Guiado"]
    )

    with tab1:
        st.markdown("### Herramientas Disponibles")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.markdown(
                """
            <div style='padding: 20px; background: rgba(176,164,97,0.1); border-radius: 10px; text-align: center;'>
                <h3>Carga de Datos</h3>
                <p>CSV y Excel</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        with col2:
            st.markdown(
                """
            <div style='padding: 20px; background: rgba(153,191,240,0.1); border-radius: 10px; text-align: center;'>
                <h3>Preprocesamiento</h3>
                <p>Limpieza y escalado</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        with col3:
            st.markdown(
                """
            <div style='padding: 20px; background: rgba(176,164,97,0.1); border-radius: 10px; text-align: center;'>
                <h3>An√°lisis PCA</h3>
                <p>Reducci√≥n de dimensiones</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        with col4:
            st.markdown(
                """
            <div style='padding: 20px; background: rgba(153,191,240,0.1); border-radius: 10px; text-align: center;'>
                <h3>Clustering</h3>
                <p>Agrupaci√≥n de datos por similitud</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        new_col1, new_col2, new_col3, new_col4 = st.columns(4)

        # Place the new content inside the first column of the new row (new_col1)
        with new_col1:
            st.markdown(
                """
                <div style='padding: 20px; background: rgba(153,191,240,0.1); border-radius: 10px; text-align: center;'>
                    <h3>ANOVA</h3>
                    <p>Comparaci√≥n de grupos</p>
                </div>
                """,
                unsafe_allow_html=True,
            )

        with new_col2:
            st.markdown(
                """
                <div style='padding: 20px; background: rgba(176,164,97,0.1); border-radius: 10px; text-align: center;'>
                    <h3>AI CHAT</h3>
                    <p>Assistente virtual</p>
                </div>
                """,
                unsafe_allow_html=True,
            )
        with new_col3:
            st.markdown(
                """
                <div style='padding: 20px; background: rgba(153,191,240,0.1); border-radius: 10px; text-align: center;'>
                    <h3>Dashboard</h3>
                    <p>Recopilaci√≥n de los gr√°ficos generados</p>
                </div>
                """,
                unsafe_allow_html=True,
            )
            # --- ADDED CODE BELOW: References Section ---
    st.markdown("---") # Second horizontal line for separation
    st.markdown("### üìö Referencias")
    st.markdown(
        """
        1. **Miller, J. N., & Miller, J. C.** (2002). *Estad√≠stica y quimiometr√≠a para qu√≠mica anal√≠tica*.  
           https://sceqa.wordpress.com/wp-content/uploads/2012/05/quimica-y-quimiometria.pdf  

        2. **Handbook of Chemometrics and Qualimetrics: Part A.** (1998).  
           https://doi.org/10.1016/s0922-3487(97)x8000-1  

        3. **Handbook of Chemometrics and Qualimetrics: Part B.** (1998).  
           https://doi.org/10.1016/s0922-3487(98)x8037-8  

        4. **LibGuides: SPSS Tutorials: One-Way ANOVA.**  
           https://libguides.library.kent.edu/spss/onewayanova  

        5. **Importancia de la homogeneidad de la varianza en ANOVA ‚Äì FasterCapital.**  
           https://fastercapital.com/es/tema/importancia-de-la-homogeneidad-de-la-varianza-en-anova.html/1  

        6. **Chugani, V.** (2024). *What is Manhattan Distance?*  
           https://www.datacamp.com/tutorial/manhattan-distance  

        7. **How to read PCA biplots and scree plots.** (2018).  
           https://bioturing.medium.com/how-to-read-pca-biplots-and-scree-plots-186246aae063
        """
    )
    # --- END OF ADDED CODE ---

    with tab2:
        st.markdown("### Fundamentos de Quimiometr√≠a")

        with st.expander("Importancia del An√°lisis Multivariante", expanded=False):
            st.markdown("""
            El an√°lisis multivariante es fundamental en qu√≠mica anal√≠tica moderna porque permite:
            
            - Trabajar simult√°neamente con m√∫ltiples variables qu√≠micas (se√±ales espectrales, concentraciones, intensidades)
            - Identificar patrones ocultos en datos complejos
            - Reducir la dimensionalidad preservando informaci√≥n qu√≠mica relevante
            - Clasificar muestras seg√∫n su composici√≥n qu√≠mica
            - Detectar correlaciones entre variables que no son evidentes en an√°lisis univariados
            """)

        with st.expander("Estandarizaci√≥n de Datos", expanded=False):
            st.markdown("""
            ### ¬øPor qu√© estandarizar?
            
            La estandarizaci√≥n transforma las variables para que tengan media cero y desviaci√≥n est√°ndar uno.
            
            #### Para el ANOVA
            
            Aunque no es estrictamente necesario para ANOVA simple, la estandarizaci√≥n es importante cuando:
            
            - **Comparabilidad entre variables:** Permite comparar la magnitud del efecto cuando se usan m√∫ltiples variables en escalas diferentes
            - **Homogeneidad de varianzas:** Puede ayudar a estabilizar varianzas cuando los grupos tienen desviaciones est√°ndar desiguales
            - **Interpretaci√≥n de coeficientes:** Facilita la comparaci√≥n en modelos de regresi√≥n subyacentes
            - **M√©todos avanzados:** Es fundamental para PCA y an√°lisis de clusters
            
            #### Para el PCA
            
            **La estandarizaci√≥n es esencial para PCA.** Si las variables no se estandarizan y una tiene varianza mucho mayor, 
            esa variable controlar√° la primera componente principal. La estandarizaci√≥n evita esto haciendo que todas las 
            variables tengan el mismo peso.
            
            En t√©rminos matem√°ticos, las componentes principales son los autovectores de la matriz de correlaci√≥n. 
            Para datos estandarizados, cada variable original tiene varianza de 1, por lo que la varianza total 
            del conjunto de datos y la suma de los autovalores son ambos iguales al n√∫mero de variables.
            
            #### Para An√°lisis de Clusters
            
            **La estandarizaci√≥n es altamente recomendada** porque la mayor√≠a de algoritmos (k-means, clustering jer√°rquico) 
            se basan en medidas de distancia sensibles a la magnitud de cada variable.
            
            Desde el punto de vista te√≥rico, la distancia Euclidiana se define como la suma de diferencias al cuadrado 
            entre variables. Una variable con escala grande domina la contribuci√≥n total de la distancia y determina 
            artificialmente la formaci√≥n de clusters. Al estandarizar, todas las variables tienen influencia equilibrada.
            """)

        with st.expander("An√°lisis de Varianza (ANOVA)", expanded=False):
            st.markdown("""
            ### ¬øQu√© es el ANOVA?
            
            El **An√°lisis de la Varianza** es una t√©cnica estad√≠stica para separar y estimar diferentes causas de variaci√≥n.
            
            **Funci√≥n principal:** Evaluar si las variaciones en la respuesta qu√≠mica (se√±ales espectrosc√≥picas, concentraciones, 
            absorbancias, intensidades) se deben realmente a factores experimentales y no al azar.
            
            ### Importancia en Quimiometr√≠a
            
            En quimiometr√≠a, el ANOVA es fundamental porque:
            
            1. **Identifica variables discriminantes:** Determina qu√© variables qu√≠micas realmente diferencian los grupos
            2. **Valida diferencias qu√≠micas:** Confirma que hay verdaderas diferencias antes del an√°lisis multivariado
            3. **Interpretaci√≥n univariada:** Relaciona directamente variables individuales (picos FAME) con fen√≥menos qu√≠micos
            4. **Detecta se√±ales responsables:** Identifica qu√© se√±ales qu√≠micas causan la variaci√≥n en PCA
            
            ### Ecuaciones Fundamentales
            
            **Suma de cuadrados total (SST):** Variabilidad total en los datos
            $SS_T = \\sum_{i=1}^{k}\\sum_{j=1}^{n_i} (y_{ij} - \\bar{y})^2$
            
            **Suma de cuadrados entre grupos (SSB):** Variabilidad explicada por diferencias entre grupos
            $SS_A = \\sum_{i=1}^{k} n_i (\\bar{y}_i - \\bar{y})^2$
            
            **Suma de cuadrados dentro de grupos (SSE):** Variabilidad interna (error o ruido)
            $SS_E = \\sum_{i=1}^{k}\\sum_{j=1}^{n_i} (y_{ij} - \\bar{y}_i)^2$
            
            **Estad√≠stico F:** Compara variabilidad explicada vs no explicada
            $F = \\frac{MS_A}{MS_E}$
            
            ### Interpretaci√≥n
            
            - **F grande:** Las diferencias entre grupos son mayores que la variabilidad aleatoria
            - **p-valor < 0.05:** Rechazamos la hip√≥tesis nula, hay diferencias significativas
            - **p-valor ‚â• 0.05:** No hay evidencia suficiente de diferencias significativas
            """)

        with st.expander("An√°lisis de Componentes Principales (PCA)", expanded=False):
            st.markdown("""
            ### ¬øQu√© es el PCA?
            
            Es una t√©cnica para **reducir la dimensionalidad** cuando existe correlaci√≥n entre variables.
            
            La idea es encontrar componentes principales Z‚ÇÅ, Z‚ÇÇ, ..., Z‚Çô que sean combinaciones lineales 
            de las variables originales X‚ÇÅ, X‚ÇÇ, ..., X‚Çô:
            
            $Z_1 = a_{11}X_1 + a_{12}X_2 + a_{13}X_3 + \\dots + a_{1n}X_n$
            
            Los coeficientes se eligen para que:
            1. Las nuevas variables no est√©n correlacionadas entre s√≠
            2. La primera componente (PC1) capture la mayor variaci√≥n
            3. La segunda (PC2) capture la siguiente mayor variaci√≥n, y as√≠ sucesivamente
            
            ### Importancia en Quimiometr√≠a
            
            PCA es central en quimiometr√≠a para explorar mezclas qu√≠micas y se√±ales multivariadas. Permite detectar:
            
            - **Agrupamientos** en los datos
            - **Variables responsables** de la diferenciaci√≥n
            - **Outliers** experimentales o qu√≠micos
            - **Relaciones entre picos** (covarianzas qu√≠micas)
            
            Los **loadings** muestran c√≥mo cada variable contribuye qu√≠micamente a las componentes principales.
            
            ### Visualizaciones Clave
            
            **Scree Plot:** Muestra varianza explicada por cada componente. La varianza explicada por el componente i es:
            $\\frac{\\lambda_i}{\\sum_{j=1}^{n} \\lambda_j}$
            
            Ayuda a decidir cu√°ntos componentes son necesarios para describir la estructura qu√≠mica.
            
            **Scores Plot:** Distribuci√≥n de muestras en el espacio de componentes principales. Muestras cercanas 
            tienen patrones similares (composiciones qu√≠micas parecidas).
            
            **Loadings Plot:** Muestra contribuci√≥n de cada variable a los componentes. Los loadings son elementos 
            de los vectores propios. Mayor valor absoluto indica mayor influencia.
            
            **Biplot:** Combina scores y loadings en una sola gr√°fica, permitiendo relacionar directamente 
            caracter√≠sticas qu√≠micas con patrones observados.
            """)

        with st.expander("An√°lisis de Clusters", expanded=False):
            st.markdown("""
            ### ¬øQu√© es el An√°lisis de Clusters?
            
            Es un m√©todo para **dividir objetos en clases** de manera que objetos similares queden en la misma clase.
            
            Como en PCA, los grupos no se conocen antes del an√°lisis. Busca objetos pr√≥ximos en el espacio de variables.
            
            **Distancia Euclidiana:**
            $d = \\sqrt{\\sum_{i=1}^n (x_i-y_i)^2}$
            
            **Distancia Manhattan:**
            $D_{Manhattan} = |x_1 - x_2| + |y_1 - y_2|$
            
            ### Importancia en Quimiometr√≠a
            
            El clustering es fundamental porque permite:
            
            - **Identificar patrones naturales** sin categor√≠as predefinidas
            - **Agrupar muestras** seg√∫n similitud qu√≠mica
            - **Detectar relaciones** no evidentes a simple vista
            - **Distinguir feedstocks** e identificar adulteraciones
            - **Evaluar calidad** de lotes y procesos
            - **Complementar PCA** asignando grupos en el espacio reducido
            - **Detectar outliers** (errores instrumentales o contaminaci√≥n)
            
            ### Visualizaciones
            
            **Dendrograma:** Muestra c√≥mo las muestras se agrupan jer√°rquicamente. La altura de uni√≥n indica 
            la diferencia qu√≠mica. Un corte horizontal permite decidir el n√∫mero de clusters.
            
            **Scatter Plot en espacio PCA:** Proyecta clusters en PC1 vs PC2, mostrando separaci√≥n espacial 
            y consistencia con la estructura qu√≠mica.
            
            ### M√©trica de Calidad: √çndice Silhouette
            
            Eval√∫a cu√°n bien definidas est√°n las clases obtenidas. Mide:
            - Separaci√≥n qu√≠mica entre grupos
            - Coherencia interna de cada grupo
            - Validaci√≥n de que las diferencias son qu√≠micamente reales
            """)

    with tab3:
        st.markdown("### Ejemplo: An√°lisis de Datos Espectrales")

        st.markdown("""
        A continuaci√≥n se presenta un flujo de trabajo t√≠pico para an√°lisis quimiom√©trico de datos espectrales:
        """)

        st.markdown("#### Paso 1: Carga de Datos")
        st.info("""
        **Acci√≥n:** Navega a "Cargar Dataset" en el panel lateral.
        
        - Sube un archivo CSV o Excel con tus datos espectrales
        - Las filas representan muestras individuales
        - Las columnas representan variables qu√≠micas (longitudes de onda, picos FAME, concentraciones)
        - Aseg√∫rate de incluir al menos una columna categ√≥rica (ej: tipo de feedstock, lote, concentraci√≥n)
        """)

        st.markdown("#### Paso 2: Preprocesamiento")
        st.info("""
        **Acci√≥n:** Ve a "Preprocesamiento de Datos"
        
        1. **Limpieza de valores nulos:** Elimina filas con datos faltantes
        2. **Eliminaci√≥n de columnas:** Remueve variables no relevantes (ej: identificadores, fechas)
        3. **Estandarizaci√≥n:** Aplica transformaci√≥n Z-score a variables num√©ricas
        
        **Importante:** La estandarizaci√≥n es esencial antes de PCA y clustering.
        """)

        st.markdown("#### Paso 3: An√°lisis ANOVA")
        st.info("""
        **Acci√≥n:** Selecciona "ANOVA" en el panel lateral
        
        - **Variable Dependiente:** Elige una variable qu√≠mica num√©rica (ej: intensidad de pico)
        - **Variable Factor:** Selecciona la variable categ√≥rica (ej: tipo de feedstock)
        - **Interpretaci√≥n:**
          - Si p < 0.05: Existen diferencias significativas entre grupos
          - Revisa el Test de Tukey para identificar qu√© pares de grupos difieren
          - Observa los box plots y violin plots para entender la distribuci√≥n
        """)

        st.markdown("#### Paso 4: An√°lisis PCA")
        st.info("""
        **Acci√≥n:** Navega a "An√°lisis PCA"
        
        1. **Selecci√≥n de variables:** Elige las columnas num√©ricas relevantes
        2. **Scree Plot:** Determina cu√°ntos componentes capturan la varianza (usualmente 2-3 para >80%)
        3. **Scores Plot:** 
           - Selecciona qu√© componentes visualizar (PC1 vs PC2, PC1 vs PC3, etc.)
           - Identifica agrupamientos de muestras similares
           - Detecta outliers (puntos muy alejados)
        4. **Loadings:** Identifica qu√© variables contribuyen m√°s a cada componente
        5. **Biplot:** Relaciona variables con la separaci√≥n de muestras
        
        **Personalizaci√≥n disponible:**
        - Cambiar paleta de colores
        - Seleccionar diferentes pares de componentes
        - Colorear por feedstock o concentraci√≥n
        """)

        st.markdown("#### Paso 5: Interpretaci√≥n Qu√≠mica")
        st.success("""
        **Integra los resultados:**
        
        - **ANOVA:** Confirma qu√© variables diferencian significativamente los grupos
        - **PCA:** Visualiza la estructura multivariada y detecta patrones
        - **Loadings:** Identifica qu√© picos o se√±ales causan la separaci√≥n
        - **Consistencia:** Verifica que los grupos en PCA correspondan con diferencias significativas en ANOVA
        
        **Ejemplo de conclusi√≥n qu√≠mica:**
        "Las muestras de feedstock A y B se separan claramente en PC1 (65% varianza), 
        principalmente debido a diferencias en las variables X1 y X5 (loadings altos). 
        El ANOVA confirma que estas diferencias son estad√≠sticamente significativas (p < 0.001)."
        """)

        st.markdown("---")
        st.markdown("#### Dataset de Ejemplo")

        # Create example dataset
        np.random.seed(42)
        n_samples = 30

        example_data = {
            "Feedstock": ["Tipo_A"] * 10 + ["Tipo_B"] * 10 + ["Tipo_C"] * 10,
            "Peak_280nm": np.concatenate(
                [
                    np.random.normal(15, 2, 10),
                    np.random.normal(25, 2, 10),
                    np.random.normal(20, 2, 10),
                ]
            ),
            "Peak_320nm": np.concatenate(
                [
                    np.random.normal(30, 3, 10),
                    np.random.normal(35, 3, 10),
                    np.random.normal(40, 3, 10),
                ]
            ),
            "Peak_450nm": np.concatenate(
                [
                    np.random.normal(50, 4, 10),
                    np.random.normal(45, 4, 10),
                    np.random.normal(55, 4, 10),
                ]
            ),
            "Peak_600nm": np.concatenate(
                [
                    np.random.normal(20, 2, 10),
                    np.random.normal(30, 2, 10),
                    np.random.normal(25, 2, 10),
                ]
            ),
        }

        example_df = pd.DataFrame(example_data)

        st.markdown("**Descarga este dataset de ejemplo para practicar:**")
        st.dataframe(example_df.head(10), use_container_width=True)

        csv_example = example_df.to_csv(index=False)
        st.download_button(
            label="Descargar Dataset de Ejemplo (CSV)",
            data=csv_example,
            file_name="ejemplo_espectros.csv",
            mime="text/csv",
        )

def kaggle_style_column_overview(df):
    st.markdown("## üìä Exploraci√≥n de Columnas")

    all_cols = df.columns.tolist()
    num_cols = len(all_cols)

    st.info("Desliza para ver m√°s columnas. ")

    # ---------- SLIDER ----------
    max_display_cols = 5

    if num_cols > max_display_cols:
        col_start_index = st.slider(
            label="",
            min_value=0,
            max_value=num_cols - max_display_cols,
            value=0,
            step=1
        )
        display_cols = all_cols[col_start_index: col_start_index + max_display_cols]
    else:
        display_cols = all_cols

    # ---------- GRID LAYOUT ----------
    streamlit_cols = st.columns(len(display_cols))

    # ---------- LOOP THROUGH COLUMNS ----------
    for i, col in enumerate(display_cols):

        with streamlit_cols[i]:

            col_data = df[col]
            is_numeric = pd.api.types.is_numeric_dtype(col_data)
            is_date = pd.api.types.is_datetime64_any_dtype(col_data)
            is_categorical = pd.api.types.is_string_dtype(col_data) or pd.api.types.is_categorical_dtype(col_data)

            # ---------- CARD ----------
            with st.container(border=True):

                # ---------------- HEADER ----------------
                st.markdown(f"### {col}")
                st.markdown(f"<div style='font-size:11px; color:#777;'>Tipo: <strong>{col_data.dtype}</strong></div>", unsafe_allow_html=True)

                # ---------- STATISTICS ----------
                unique_val = col_data.nunique()
                nulls_val = col_data.isna().sum()

                stat_html = f"""
                    <div style="font-size:11px; line-height:1.3;">
                    üîπ <strong>Valores √∫nicos:</strong> {unique_val}<br>
                    üîπ <strong>Nulos:</strong> {nulls_val}<br>
                """

                if is_numeric:
                    stat_html += f"""
                    üîπ <strong>Min:</strong> {col_data.min()}<br>
                    üîπ <strong>Max:</strong> {col_data.max()}
                    """

                stat_html += "</div>"

                st.markdown(stat_html, unsafe_allow_html=True)

                # ---------- PLOTTING ----------
                if is_numeric:
                    fig = px.histogram(
                        df,
                        x=col,
                        nbins=20,
                        height=150
                    )
                    fig.update_layout(
                        margin=dict(l=0, r=0, t=20, b=20),
                        xaxis_title="Valor",
                        yaxis_title="Frecuencia",
                        bargap=0.05
                    )

                elif is_categorical:
                    counts = col_data.value_counts().head(5)
                    fig = px.bar(
                        x=counts.index.astype(str),
                        y=counts.values,
                        height=150,
                        labels={"x": "Categor√≠a", "y": "Frecuencia"}
                    )
                    fig.update_layout(margin=dict(l=0, r=0, t=20, b=20))

                elif is_date:
                    temp = col_data.dropna().value_counts().sort_index()
                    fig = px.line(
                        x=temp.index,
                        y=temp.values,
                        height=150,
                        labels={"x": "Fecha", "y": "Frecuencia"}
                    )
                    fig.update_layout(margin=dict(l=0, r=0, t=20, b=20))

                else:
                    st.warning("No se puede graficar este tipo.")
                    continue

                st.plotly_chart(fig, use_container_width=True)

                # ---------- SAMPLE VALUES ----------
                st.markdown("---")
                st.markdown("**üîç Muestras etiquetadas:**")

                samples = col_data.dropna().head(3).tolist()

                sample_html = "<div style='font-size:11px; line-height:1.4;'>"
                for idx, value in enumerate(samples, start=1):
                    sample_html += f"üî∏ <strong>Valor {idx}:</strong> {value}<br>"
                sample_html += "</div>"

                st.markdown(sample_html, unsafe_allow_html=True)

def cargar_dataset():
    st.header("üìÇ Cargar Dataset")

    uploaded_file = st.file_uploader(
        "Arrastra o selecciona tu archivo CSV o Excel",
        type=["csv", "xlsx", "xls"],
        help="Formatos soportados: CSV, XLSX, XLS",
    )

    if uploaded_file:
        dataset_model = DatasetModel()

        with st.spinner("Cargando archivo..."):
            if uploaded_file.name.endswith(".csv"):
                success, error = dataset_model.load_csv(uploaded_file)
            elif uploaded_file.name.endswith((".xlsx", ".xls")):
                success, error = dataset_model.load_excel(uploaded_file)
            else:
                success = False
                error = "Unsupported file format"

        if success:
            st.session_state.df = dataset_model.df
            st.success("‚úÖ ¬°Archivo cargado exitosamente!")

            # Dataset overview
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üìã Filas", dataset_model.df.shape[0])
            with col2:
                st.metric("üìä Columnas", dataset_model.df.shape[1])
            with col3:
                st.metric(
                    "üíæ Tama√±o",
                    f"{dataset_model.df.memory_usage(deep=True).sum() / 1024:.1f} KB",
                )

            st.markdown("### üëÅÔ∏è Vista Previa de los Datos")
            st.dataframe(dataset_model.df.head(10), use_container_width=True)

            # Statistical summary
            st.markdown("## üìä Resumen Estad√≠stico B√°sico")

            stats = dataset_model.get_summary_stats()
            if stats:
                tab1, tab2 = st.tabs(["üìå Tendencia Central", "üìê Dispersi√≥n"])

                with tab1:
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.markdown("**üìç Media**")
                        st.dataframe(stats["mean"], use_container_width=True)

                    with col2:
                        st.markdown("**üéØ Mediana**")
                        st.dataframe(stats["median"], use_container_width=True)

                    with col3:
                        st.markdown("**üî¢ Moda**")
                        st.dataframe(stats["mode"], use_container_width=True)

                with tab2:
                    col1, col2 = st.columns(2)

                    with col1:
                        st.markdown("**üìè Rango**")
                        st.dataframe(stats.get("range"), use_container_width=True)

                        st.markdown("**üìä Desviaci√≥n Est√°ndar**")
                        st.dataframe(stats["std"], use_container_width=True)

                    with col2:
                        st.markdown("**üìà Varianza**")
                        st.dataframe(stats["var"], use_container_width=True)

                        st.markdown("**üì¶ Rango Intercuart√≠lico (IQR)**")
                        st.dataframe(stats["iqr"], use_container_width=True)

            st.markdown("---")

            # ‚úÖ FIXED ‚Üí PASS THE DATAFRAME, NOT THE MODEL
            kaggle_style_column_overview(dataset_model.df)

            st.markdown("---")

            col1, col2, col3 = st.columns([1, 1, 1])
            with col2:
                if st.button(
                    "‚û°Ô∏è Ir a Preprocesamiento de Datos",
                    type="primary",
                    use_container_width=True,
                ):
                    st.session_state.page = "Preprocesamiento de Datos"
                    st.rerun()
        else:
            st.error(f"‚ùå Error: {error}")

def impute_median(columns=None):
    """
    Imputa NaN en columnas num√©ricas con la mediana.
    """
    df = st.session_state.df.copy()
    imputed_counts = {}

    try:
        if columns is None:
            cols = df.select_dtypes(include=[np.number]).columns.tolist()
        else:
            cols = [c for c in columns if c in df.columns]

        for col in cols:
            n_before = df[col].isnull().sum()
            if n_before > 0:
                med = df[col].median()

                if pd.isna(med):
                    imputed_counts[col] = 0
                    continue

                df[col] = df[col].fillna(med)
                n_after = df[col].isnull().sum()
                imputed_counts[col] = n_before - n_after
            else:
                imputed_counts[col] = 0

        st.session_state.df = df
        return imputed_counts

    except Exception as e:
        st.error(f"Error durante la imputaci√≥n con mediana: {e}")
        return {}


def impute_mode(columns=None):
    """
    Imputa NaN en columnas num√©ricas o categ√≥ricas con la moda.
    """
    df = st.session_state.df.copy()
    imputed_counts = {}

    try:
        if columns is None:
            cols = df.columns.tolist()
        else:
            cols = [c for c in columns if c in df.columns]

        for col in cols:
            n_before = df[col].isnull().sum()

            if n_before > 0:
                modes = df[col].mode(dropna=True)

                if modes.empty:
                    imputed_counts[col] = 0
                    continue

                mode_val = modes.iloc[0]
                df[col] = df[col].fillna(mode_val)

                n_after = df[col].isnull().sum()
                imputed_counts[col] = n_before - n_after
            else:
                imputed_counts[col] = 0

        st.session_state.df = df
        return imputed_counts

    except Exception as e:
        st.error(f"Error durante la imputaci√≥n con moda: {e}")
        return {}
    
def preprocessing_page():
    st.header("üîß Preprocesamiento de Datos")

    if st.session_state.df is None:
        st.warning("‚ö†Ô∏è A√∫n no has cargado un dataset.")
        if st.button("‚¨ÖÔ∏è Regresar a cargar dataset"):
            st.session_state.page = "Cargar dataset"
            st.rerun()
        return

    # ----------------------------
    # INITIALIZE LOGGING VARIABLES
    # ----------------------------
    if "df_before" not in st.session_state:
        st.session_state.df_before = st.session_state.df.copy()

    if "changes_log" not in st.session_state:
        st.session_state.changes_log = []

    if "show_pca_after_standardize" not in st.session_state:
        st.session_state.show_pca_after_standardize = False

    preprocessing_model = PreprocessingModel(st.session_state.df)

    # ----------------------------
    # CREATE TABS
    # ----------------------------
    tab1, tab2 = st.tabs(["‚öôÔ∏è Preprocesamiento", "üîç Antes & Despu√©s"])

    # ------------------------------------------------------------------
    # ===================== TAB 1: PREPROCESSING =======================
    # ------------------------------------------------------------------
    with tab1:

        current_rows, current_cols = preprocessing_model.df.shape

        col1, col2 = st.columns(2)
        with col1:
            st.metric("üìã Filas actuales", current_rows)
        with col2:
            st.metric("üìä Columnas actuales", current_cols)

        st.dataframe(preprocessing_model.df.head(), use_container_width=True)

        st.markdown("---")

        # ======== CLEANING NA ========
        with st.expander("üßπ Limpieza de Valores Nulos (NaN)", expanded=True):
            initial_nan = preprocessing_model.df.isnull().any(axis=1).sum()
            st.metric("Filas con valores nulos", initial_nan)

            if st.button("üóëÔ∏è Eliminar filas con NaN", key="clean_btn"):
                dropped = preprocessing_model.drop_na()
                st.session_state.df = preprocessing_model.df

                st.session_state.changes_log.append(
                    f"üóëÔ∏è Eliminadas {dropped} filas con NaN."
                )

                st.success(f"‚úÖ Se eliminaron **{dropped}** filas.")
                st.rerun()

        # ======== IMPUTATION ========
        with st.expander("üß© Imputaci√≥n de Valores Nulos", expanded=False):

            df = preprocessing_model.df
            nan_cols = df.columns[df.isnull().any()].tolist()

            st.write(f"Columnas con NaN restantes: **{', '.join(nan_cols)}**")

            metodo = st.radio(
                "M√©todo de imputaci√≥n:",
                ("Mediana", "Moda"),
                horizontal=True
            )

            if st.button("‚ú® Imputar Valores", key="impute_btn"):

                if metodo == "Mediana":
                    imputed_counts = impute_median(columns=nan_cols)
                    method_name = "la mediana"
                else:
                    imputed_counts = impute_mode(columns=nan_cols)
                    method_name = "la moda"

                total = sum(imputed_counts.values())

                st.session_state.changes_log.append(
                    f"üß© Imputados {total} valores usando {method_name}."
                )

                if total > 0:
                    st.success(f"üìå {total} valores imputados.")
                st.rerun()

        # ======== STANDARDIZATION ========
        with st.expander("üìè Estandarizaci√≥n (Z-Score)", expanded=True):

            numerical_cols = preprocessing_model.get_numerical_columns()

            st.info(f"**Columnas num√©ricas detectadas:** {', '.join(numerical_cols)}")

            if st.button("‚ö° Estandarizar Columnas Num√©ricas", key="standardize_btn"):
                preprocessing_model.standardize(numerical_cols)
                st.session_state.df = preprocessing_model.df
                st.session_state.standardized = True
                st.session_state.show_pca_after_standardize = True

                st.session_state.changes_log.append(
                    "üìè Columnas num√©ricas estandarizadas (Z-score)."
                )

                st.success("¬°Estandarizaci√≥n completada!")

            # ‚òÖ NEW: Button appears immediately after standardizing
            if st.session_state.show_pca_after_standardize:
                st.info("Ahora puedes continuar con el an√°lisis PCA.")
                if st.button("‚û°Ô∏è Ir a An√°lisis PCA", key="go_pca_after_std", type="primary"):
                    st.session_state.page = "PCA"
                    st.session_state.show_pca_after_standardize = False
                    st.rerun()

        # Persistent PCA button once dataset is standardized
        if st.session_state.get("standardized"):
            st.success("‚úÖ El dataset ya fue estandarizado.")

            col1, col2, col3 = st.columns([1, 1, 1])
            with col2:
                if st.button(
                    "‚û°Ô∏è Ir a An√°lisis PCA",
                    key="go_pca_standardized_persistent",
                    type="primary",
                    use_container_width=True
                ):
                    st.session_state.page = "PCA"
                    st.rerun()

    # ------------------------------------------------------------------
    # ===================== TAB 2: BEFORE & AFTER ======================
    # ------------------------------------------------------------------
    with tab2:
        st.subheader("üîç Comparaci√≥n Antes vs Despu√©s")

        df_before = st.session_state.df_before
        df_after = st.session_state.df

        c1, c2 = st.columns(2)
        with c1:
            st.metric("Filas antes", df_before.shape[0])
            st.metric("Columnas antes", df_before.shape[1])
        with c2:
            st.metric("Filas despu√©s", df_after.shape[0])
            st.metric("Columnas despu√©s", df_after.shape[1])

        st.markdown("---")

        # ======== LOG OF CHANGES ========
        st.subheader("üìú Registro de Cambios Aplicados")
        if len(st.session_state.changes_log) == 0:
            st.info("Sin cambios a√∫n.")
        else:
            for entry in st.session_state.changes_log:
                st.write(entry)

        st.markdown("---")

        # ======== SHOW DATAFRAMES ========
        st.subheader("üìä Dataset Antes")
        st.dataframe(df_before.head(), use_container_width=True)

        st.subheader("üìä Dataset Despu√©s")
        st.dataframe(df_after.head(), use_container_width=True)


def pca_page():
    st.header("üìà An√°lisis de Componentes Principales (PCA)")

    with st.expander("‚ÑπÔ∏è ¬øQu√© es el PCA?", expanded=False):
        st.markdown("""
        El **An√°lisis de Componentes Principales (PCA)** es una t√©cnica de reducci√≥n de dimensionalidad que:
        
        - üéØ Transforma variables correlacionadas en componentes independientes
        - üìä Captura la mayor varianza posible en menos dimensiones
        - üîç Facilita la visualizaci√≥n de datos multidimensionales
        - ‚ö° Mejora el rendimiento de modelos de machine learning
        
        **Importante:** Los datos deben estar estandarizados antes de aplicar PCA.
        """)

    COLOR_PALETTES = {
        "QuimioAnalytics (Custom)": [
            "#B0A461",
            "#4A525A",
            "#E0D7B2",
            "#2E3339",
            "#8E9E9A",
        ],
        "Viridis (Default)": "viridis",
        "Plasma": "plasma",
        "Cividis": "cividis",
        "Inferno": "inferno",
        "Magma": "magma",
        "Cool Warm": ["#0000FF", "#87CEEB", "#FFFFFF", "#FF6347", "#FF0000"],
        "Greyscale": ["#000000", "#555555", "#AAAAAA", "#CCCCCC", "#FFFFFF"],
    }

    if st.session_state.df is None:
        st.warning("‚ö†Ô∏è Carga un dataset primero.")
        return

    df_pca = st.session_state.df.copy()
    numeric_cols = df_pca.select_dtypes(include=[np.number]).columns.tolist()

    if not numeric_cols:
        st.error("‚ùå No hay columnas num√©ricas en el dataset.")
        return

    if not st.session_state.get("standardized", False):
        st.warning("‚ö†Ô∏è Debes estandarizar los datos antes de realizar PCA.")
        return

    col1, col2 = st.columns([2, 1])

    with col1:
        selected_columns = st.multiselect(
            "üéØ Selecciona columnas num√©ricas para PCA:",
            numeric_cols,
            default=numeric_cols,
        )

    with col2:
        st.session_state.plot_color_choice = st.selectbox(
            "üé® Paleta de colores:",
            list(COLOR_PALETTES.keys()),
            index=list(COLOR_PALETTES.keys()).index(st.session_state.plot_color_choice),
        )

    if len(selected_columns) < 2:
        st.warning("‚ö†Ô∏è Selecciona al menos 2 columnas para aplicar PCA.")
        return

    if st.button("‚ñ∂Ô∏è Aplicar PCA", key="run_pca", type="primary"):
        st.session_state.pca_ready = True
        st.session_state.pca_columns = selected_columns
        st.rerun()

    if st.session_state.get("pca_ready", False):
        pca_model = PCAModel(df_pca, st.session_state.pca_columns)
        pca_model.fit_pca()

        st.success("‚úÖ PCA aplicado correctamente")

        # Tabs for different analyses
        tab1, tab2, tab3, tab4, tab5 = st.tabs(
            [
                "üìä Varianza Explicada",
                "üéØ Gr√°fico de Componentes",
                "üîó Biplot",
                "üîç Loadings",
                "üìã Datos Transformados",
            ]
        )

        with tab1:
            st.subheader("Scree Plot - Varianza Explicada")

            df_var = pca_model.get_scree_data()

            palette = COLOR_PALETTES[st.session_state.plot_color_choice]

            fig = go.Figure()

            fig.add_trace(
                go.Bar(
                    x=df_var["Componente"],
                    y=df_var["Varianza (%)"],
                    name="Varianza Individual",
                    marker_color="#B0A461",
                )
            )

            fig.add_trace(
                go.Scatter(
                    x=df_var["Componente"],
                    y=df_var["Acumulada (%)"],
                    mode="lines+markers",
                    name="Varianza Acumulada",
                    line=dict(color="#4A525A", width=3),
                    marker=dict(size=10),
                )
            )

            fig.update_layout(
                title="Varianza Explicada por Componente Principal",
                xaxis_title="Componente",
                yaxis_title="Varianza (%)",
                hovermode="x unified",
                template="plotly_white",
            )

            st.plotly_chart(fig, use_container_width=True)
            st.session_state.setdefault("dashboard_pca", []).append(fig)

            st.dataframe(df_var, use_container_width=True)

        with tab2:
            st.subheader("Visualizaci√≥n de Componentes Principales")

            if pca_model.pc_values.shape[1] >= 2:
                col1, col2 = st.columns(2)

                with col1:
                    pc_x = st.selectbox(
                        "Componente X:",
                        [f"PC{i + 1}" for i in range(pca_model.pc_values.shape[1])],
                        index=0,
                    )

                with col2:
                    pc_y = st.selectbox(
                        "Componente Y:",
                        [f"PC{i + 1}" for i in range(pca_model.pc_values.shape[1])],
                        index=1,
                    )

                palette = COLOR_PALETTES[st.session_state.plot_color_choice]

                fig_scatter = pca_model.get_scores_plot(pc_x, pc_y, palette)

                st.plotly_chart(fig_scatter, use_container_width=True)
                st.session_state.setdefault("dashboard_pca", []).append(fig_scatter)

                pc_x_idx = int(pc_x.replace("PC", "")) - 1
                pc_y_idx = int(pc_y.replace("PC", "")) - 1
                col1, col2 = st.columns(2)
                with col1:
                    st.metric(
                        f"Varianza {pc_x}",
                        f"{pca_model.explained[pc_x_idx] * 100:.2f}%",
                    )
                with col2:
                    st.metric(
                        f"Varianza {pc_y}",
                        f"{pca_model.explained[pc_y_idx] * 100:.2f}%",
                    )

        with tab3:
            st.subheader("Biplot - Scores y Loadings Combinados")

            st.markdown("""
            El **biplot** combina las puntuaciones (scores) de las muestras con las cargas (loadings) de las variables.
            Permite identificar qu√© variables son responsables de las agrupaciones observadas en las muestras.
            """)

            if pca_model.pc_values.shape[1] >= 2:
                col1, col2 = st.columns(2)

                with col1:
                    pc_x_bi = st.selectbox(
                        "Componente X:",
                        [f"PC{i + 1}" for i in range(pca_model.pc_values.shape[1])],
                        index=0,
                        key="biplot_x",
                    )

                with col2:
                    pc_y_bi = st.selectbox(
                        "Componente Y:",
                        [f"PC{i + 1}" for i in range(pca_model.pc_values.shape[1])],
                        index=1,
                        key="biplot_y",
                    )

                fig_biplot = pca_model.get_biplot(
                    pc_x_bi, pc_y_bi, COLOR_PALETTES[st.session_state.plot_color_choice]
                )

                st.plotly_chart(fig_biplot, use_container_width=True)
                st.session_state.setdefault("dashboard_pca", []).append(fig_biplot)

                st.markdown("### Interpretaci√≥n del Biplot")
                st.info("""
                **C√≥mo leer el biplot:**
                
                - **Puntos (Muestras):** Representan las observaciones proyectadas en el espacio de componentes principales
                - **Vectores (Variables):** Muestran la direcci√≥n y magnitud de la contribuci√≥n de cada variable
                - **√Ångulos entre vectores:**
                  - √Ångulo peque√±o (< 30¬∞): Variables positivamente correlacionadas
                  - √Ångulo cercano a 90¬∞: Variables no correlacionadas
                  - √Ångulo cercano a 180¬∞: Variables negativamente correlacionadas
                - **Longitud del vector:** Indica cu√°n bien est√° representada la variable en estas componentes
                - **Direcci√≥n muestra-variable:** Si una muestra est√° en la direcci√≥n de un vector, tiene valores altos en esa variable
                """)

        with tab4:
            st.subheader("Matriz de Loadings")
            st.markdown(
                "Los **loadings** muestran la contribuci√≥n de cada variable original a cada componente principal."
            )

            loadings_df = pca_model.get_loadings_df()

            st.dataframe(
                loadings_df.style.background_gradient(cmap="RdYlGn", axis=None),
                use_container_width=True,
            )

            # Heatmap de loadings
            fig_heatmap = px.imshow(
                loadings_df.T,
                labels=dict(x="Variables", y="Componentes", color="Loading"),
                x=loadings_df.index,
                y=loadings_df.columns,
                color_continuous_scale="RdBu_r",
                aspect="auto",
            )
            fig_heatmap.update_layout(title="Heatmap de Loadings")
            st.plotly_chart(fig_heatmap, use_container_width=True)
            st.session_state.setdefault("dashboard_pca", []).append(fig_heatmap)

        with tab5:
            st.subheader("Datos Transformados (Scores)")

            pc_df = pca_model.get_transformed_df()

            st.dataframe(pc_df.head(20), use_container_width=True)

            csv = pc_df.to_csv(index=False)
            st.download_button(
                label="üì• Descargar datos PCA (CSV)",
                data=csv,
                file_name="pca_transformed.csv",
                mime="text/csv",
            )

        st.markdown("---")
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            if st.button(
                "‚û°Ô∏è Ir a Clustering",
                key="to_clustering",
                type="primary",
                use_container_width=True,
            ):
                st.session_state.page = "Clustering"
                st.session_state.pca_ready = False
                st.rerun()


def cluster_page():
    st.header("üçá Clustering")

    with st.expander("‚ÑπÔ∏è ¬øQu√© es el Clustering?", expanded=False):
        st.markdown("""
        El **Clustering** es una t√©cnica de aprendizaje no supervisado que agrupa datos similares en "cl√∫steres" o grupos para identificar patrones y estructuras ocultas. 
        
        - üéØ Su objetivo es que los puntos de datos dentro de un mismo grupo sean m√°s parecidos entre s√≠ que con los de otros grupos, sin tener una etiqueta previa. 
        
        """)

    # Check dataset
    if "df" not in st.session_state or st.session_state.df is None:
        st.warning("‚ö†Ô∏è A√∫n no has cargado un dataset.")
        return

    df = st.session_state.df.copy()

    COLOR_PALETTES = {
        "QuimioAnalytics (Custom)": [
            "#B0A461",
            "#4A525A",
            "#E0D7B2",
            "#2E3339",
            "#8E9E9A",
        ],
        "Viridis (Default)": "viridis",
        "Plasma": "plasma",
        "Cividis": "cividis",
        "Inferno": "inferno",
        "Magma": "magma",
        "Cool Warm": ["#0000FF", "#87CEEB", "#FFFFFF", "#FF6347", "#FF0000"],
        "Greyscale": ["#000000", "#555555", "#AAAAAA", "#CCCCCC", "#FFFFFF"],
    }

    palette = COLOR_PALETTES.get(
        st.session_state.get("plot_color_choice", "QuimioAnalytics (Custom)")
    )

    st.markdown("---")

    # ================================================
    # üî¢ NUMERICAL COLUMNS
    # ================================================
    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if not numerical_cols:
        st.error("‚ùå No hay columnas num√©ricas para clustering.")
        return

    # ================================================
    # üéØ PCA Projection (Consistent with PCA Page)
    # ================================================
    st.subheader("üìâ Proyecci√≥n PCA para Visualizaci√≥n de Cl√∫steres")

    if st.session_state.get("pca_ready", False):
        try:
            # Use the PCA computed in pca_page
            columns = st.session_state.pca_columns
            X = df[columns].values
            pca = PCA(n_components=2)
            proj = pca.fit_transform(X)

            df["PC1"] = proj[:, 0]
            df["PC2"] = proj[:, 1]

            st.success("üéØ Usando PCA seleccionado en la p√°gina anterior.")
        except:
            st.error("El PCA previo no fue compatible. Se recalcular√°.")
            pca = PCA(n_components=2)
            proj = pca.fit_transform(df[numerical_cols])
            df["PC1"] = proj[:, 0]
            df["PC2"] = proj[:, 1]
    else:
        # Compute PCA from scratch for visualization
        pca = PCA(n_components=2)
        proj = pca.fit_transform(df[numerical_cols])
        df["PC1"] = proj[:, 0]
        df["PC2"] = proj[:, 1]

    # ================================================
    # üî∑ K-MEANS SECTION
    # ================================================
    with st.expander("üìå K-Means Clustering", expanded=True):
        k = st.slider("N√∫mero de clusters (k)", 2, 12, 3)
        n_init = st.slider("Repeticiones (n_init)", 5, 30, 10)
        init_method = st.selectbox("M√©todo de inicializaci√≥n", ["k-means++"])

        if st.button("üöÄ Ejecutar K-Means", type="primary", key="run_kmeans"):
            try:
                clustering_model = ClusteringModel(df, numerical_cols)
                labels, sil_score = clustering_model.kmeans_cluster(
                    k, n_init, init_method
                )
                df["Cluster_KMeans"] = labels

                st.success(
                    f"‚úÖ K-Means completado. Silhouette Score: **{sil_score:.4f}**"
                )

                fig = px.scatter(
                    df,
                    x="PC1",
                    y="PC2",
                    color="Cluster_KMeans",
                    title="Cl√∫steres K-Means proyectados en espacio PCA",
                    opacity=0.85,
                    color_discrete_sequence=palette
                    if isinstance(palette, list)
                    else None,
                )
                st.plotly_chart(fig, use_container_width=True)
                st.session_state.setdefault("dashboard_cluster", []).append(fig)

                st.subheader("üìä Resumen por Cl√∫ster")
                summary = df.groupby("Cluster_KMeans")[numerical_cols].mean()
                st.dataframe(summary, use_container_width=True)

            except Exception as e:
                st.error(f"‚ùå Error ejecutando K-Means: {e}")

    # ================================================
    # üåø HIERARCHICAL CLUSTERING
    # ================================================
    with st.expander("üåø Clustering Jer√°rquico"):
        linkage_method = st.selectbox(
            "M√©todo de enlace (linkage)", ["single", "complete", "average", "ward"]
        )

        num_clusters_h = st.slider("N√∫mero de clusters", 2, 12, 3, key="clusters_hier")

        if st.button("üå± Ejecutar Clustering Jer√°rquico", key="run_hier"):
            try:
                clustering_model = ClusteringModel(df, numerical_cols)
                labels = clustering_model.hierarchical_cluster(
                    linkage_method, num_clusters_h
                )
                df["Cluster_Hier"] = labels

                st.success("‚úÖ Clustering jer√°rquico completado.")

                fig2 = px.scatter(
                    df,
                    x="PC1",
                    y="PC2",
                    color="Cluster_Hier",
                    title="Cl√∫steres Jer√°rquicos proyectados en espacio PCA",
                    opacity=0.85,
                    color_discrete_sequence=palette
                    if isinstance(palette, list)
                    else None,
                )
                st.plotly_chart(fig2, use_container_width=True)
                st.session_state.setdefault("dashboard_cluster", []).append(fig2)

                st.subheader("üìä Resumen por Cl√∫ster")
                st.dataframe(
                    df.groupby("Cluster_Hier")[numerical_cols].mean(),
                    use_container_width=True,
                )

                st.subheader("üå≥ Dendrograma")
                try:
                    fig_d = clustering_model.get_dendrogram(linkage_method)
                    st.plotly_chart(fig_d, use_container_width=True)
                    st.session_state.setdefault("dashboard_cluster", []).append(fig_d)
                except Exception as dendro_error:
                    st.error(f"No se pudo generar el dendrograma: {dendro_error}")

            except Exception as e:
                st.error(f"‚ùå Error ejecutando clustering jer√°rquico: {e}")

    # ================================================
    # NAVIGATION
    # ================================================
    st.markdown("---")
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        if st.button("‚û°Ô∏è Ir a ANOVA", type="primary"):
            st.session_state.page = "ANOVA"
            st.rerun()


def anova_page():
    st.header("üßÆ An√°lisis de Varianza (ANOVA)")

    # Initialize flag
    if "anova_done" not in st.session_state:
        st.session_state.anova_done = False

    with st.expander("‚ÑπÔ∏è ¬øQu√© es el ANOVA?", expanded=False):
        st.markdown("""
        El ANOVA ...
        """)

    COLOR_PALETTES = {
        "QuimioAnalytics (Custom)": [
            "#B0A461",
            "#4A525A",
            "#E0D7B2",
            "#2E3339",
            "#8E9E9A",
        ],
        "Viridis (Default)": "viridis",
        "Plasma": "plasma",
        "Cividis": "cividis",
        "Inferno": "inferno",
        "Magma": "magma",
        "Cool Warm": ["#0000FF", "#87CEEB", "#FFFFFF", "#FF6347", "#FF0000"],
        "Greyscale": ["#000000", "#555555", "#AAAAAA", "#CCCCCC", "#FFFFFF"],
    }

    if st.session_state.df is None:
        st.warning("‚ö†Ô∏è Carga un dataset primero.")
        return

    df_anova = st.session_state.df.copy()

    if "plot_color_choice" not in st.session_state:
        st.session_state.plot_color_choice = "QuimioAnalytics (Custom)"

    numerical_cols = df_anova.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df_anova.select_dtypes(
        include=["object", "category"]
    ).columns.tolist()

    if not numerical_cols or not categorical_cols:
        st.error(
            "‚ùå Se necesita al menos una columna num√©rica y una categ√≥rica para ANOVA."
        )
        return

    col1, col2, col3 = st.columns([2, 2, 1])

    with col1:
        y_var = st.selectbox(
            "üéØ Variable Dependiente (Num√©rica):", numerical_cols, key="anova_y"
        )

    with col2:
        x_var = st.selectbox(
            "üè∑Ô∏è Variable Factor/Grupo (Categ√≥rica):", categorical_cols, key="anova_x"
        )

    with col3:
        st.session_state.plot_color_choice = st.selectbox(
            "üé® Paleta:",
            list(COLOR_PALETTES.keys()),
            index=list(COLOR_PALETTES.keys()).index(st.session_state.plot_color_choice),
        )

    st.markdown("---")

    # --------------------------------------------------
    # ‚ñ∂Ô∏è APPLY ANOVA (kept exactly as you had it)
    # --------------------------------------------------

    if st.button("‚ñ∂Ô∏è Aplicar ANOVA", type="primary"):
        anova_model = ANOVAModel(df_anova, y_var, x_var)
        try:
            anova_table, df_model = anova_model.compute_anova()

            st.success("‚úÖ ANOVA completado")

            # Store values so the button can work later
            st.session_state.anova_done = True
            st.session_state.anova_table = anova_table
            st.session_state.df_model = df_model
            st.session_state.y_var = y_var
            st.session_state.x_var = x_var
            st.session_state.anova_model = anova_model

        except Exception as e:
            st.error(f"‚ùå Error al calcular ANOVA: {e}")
            return

    # --------------------------------------------------
    # SHOW THE AI CHAT BUTTON ONLY IF ANOVA WAS RUN
    # --------------------------------------------------

    if st.session_state.anova_done:
        st.markdown("---")
        colA, colB, colC = st.columns([1, 1, 1])
        with colB:
            if st.button(
                "‚û°Ô∏è Ir con Heisenberg", type="primary", use_container_width=True
            ):
                st.session_state.page = "AI Chat"
                st.rerun()

        # --------------------------------------------------
        # Now show all tabs normally (your original code)
        # --------------------------------------------------
        anova_table = st.session_state.anova_table
        df_model = st.session_state.df_model
        y_var = st.session_state.y_var
        x_var = st.session_state.x_var

        tab1, tab2, tab3, tab4 = st.tabs(
            [
                "üìä Tabla ANOVA",
                "üìà Visualizaciones",
                "üîç Test Post-Hoc",
                "üìã Estad√≠sticas Descriptivas",
            ]
        )

        with tab1:
            st.subheader("Tabla de An√°lisis de Varianza")
            st.dataframe(anova_table, use_container_width=True)

            # Interpretation
            try:
                p_value = anova_table.loc[x_var, "PR(>F)"]
                if p_value < 0.05:
                    st.success(
                        f"‚úÖ **Resultado significativo** (p = {p_value:.4f} < 0.05)"
                    )
                    st.info(
                        "Hay diferencias estad√≠sticamente significativas entre los grupos."
                    )
                else:
                    st.warning(
                        f"‚ö†Ô∏è **Resultado no significativo** (p = {p_value:.4f} ‚â• 0.05)"
                    )
                    st.info(
                        "No hay evidencia suficiente de diferencias significativas entre los grupos."
                    )
            except KeyError:
                st.error(
                    "‚ùå No se pudo obtener el valor p de la tabla ANOVA. Verifique los datos y variables seleccionadas."
                )

        with tab2:
            st.subheader("Visualizaciones")

            palette = COLOR_PALETTES[st.session_state.plot_color_choice]

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**Box Plot**")
                fig_box = px.box(
                    df_model,
                    x=x_var,
                    y=y_var,
                    color=x_var,
                    title=f"Distribuci√≥n de {y_var} por {x_var}",
                    color_discrete_sequence=palette
                    if isinstance(palette, list)
                    else None,
                )
                fig_box.update_layout(showlegend=False)
                st.plotly_chart(fig_box, use_container_width=True)
                st.session_state.setdefault("dashboard_anova", []).append(fig_box)

            with col2:
                st.markdown("**Violin Plot**")
                fig_violin = px.violin(
                    df_model,
                    x=x_var,
                    y=y_var,
                    color=x_var,
                    title=f"Distribuci√≥n de {y_var} por {x_var}",
                    color_discrete_sequence=palette
                    if isinstance(palette, list)
                    else None,
                )
                fig_violin.update_layout(showlegend=False)
                st.plotly_chart(fig_violin, use_container_width=True)
                st.session_state.setdefault("dashboard_anova", []).append(fig_violin)

        with tab3:
            st.subheader("Test Post-Hoc: Tukey HSD")

            try:
                anova_model = st.session_state.anova_model
                tukey = anova_model.tukey_test(df_model)

                st.markdown("**Comparaciones pareadas entre grupos:**")
                tukey_df = pd.DataFrame(
                    {
                        "Grupo 1": tukey.groupsunique[tukey.group1],
                        "Grupo 2": tukey.groupsunique[tukey.group2],
                        "Diferencia de Medias": tukey.meandiffs,
                        "p-valor": tukey.pvalues,
                        "Rechaza H0": tukey.reject,
                    }
                )

                st.dataframe(tukey_df, use_container_width=True)

                # Highlight significant differences
                significant = tukey_df[tukey_df["Rechaza H0"] == True]
                if not significant.empty:
                    st.success("üîç **Diferencias significativas encontradas:**")
                    for _, row in significant.iterrows():
                        st.write(
                            f"- {row['Grupo 1']} vs {row['Grupo 2']}: p = {row['p-valor']:.4f}"
                        )
                else:
                    st.info(
                        "‚ÑπÔ∏è No se encontraron diferencias significativas entre pares espec√≠ficos de grupos."
                    )

            except Exception as e:
                st.error(f"Error calculando Tukey HSD: {e}")

        with tab4:
            st.subheader("Estad√≠sticas Descriptivas por Grupo")

            desc_stats = df_model.groupby(x_var)[y_var].describe()
            st.dataframe(desc_stats, use_container_width=True)


def ai_chat_page():
    st.header("üí¨ Chat de I.A.")

    # Check dataset
    if st.session_state.df is None:
        st.warning("‚ö†Ô∏è Carga un dataset primero.")
        return

    df = st.session_state.df

    # Load image safely
    img_path = pathlib.Path("man.png")
    img_data_uri = None

    try:
        with img_path.open("rb") as f:
            data = f.read()
            b64 = base64.b64encode(data).decode("utf-8")
            img_data_uri = f"data:image/png;base64,{b64}"
    except Exception as e:
        st.warning(f"No se pudo cargar man.png ({e}).")

    # ----------- CSS (fixed version) ----------
    st.markdown(
        f"""
        <style>
        .floating-image-container {{
            position: fixed;
            top: 500px;
            right: 25px;
            width: 80px;
            z-index: 9999;
            text-align: center;
        }}
        
        .floating-image-container img {{
            width: 100%;
            height: auto;
            border-radius: 0px;
            box-shadow: 0 0px 0px rgba(0,0,0,0);
            display: block;
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )

    # ----------- Insert floating image (fixed) -----------
    if img_data_uri:
        st.markdown(
            f"""
            <div class="floating-image-container">
                <img src="{img_data_uri}">
            </div>
            """,
            unsafe_allow_html=True,
        )
    else:
        # fallback
        st.image("man.png", width=150)

    # -------------------------
    # Initialize session state
    # -------------------------
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    if "clear_input" not in st.session_state:
        st.session_state.clear_input = False

    # --- The input processing logic needs to stay at the top for the rerun to work correctly. ---

    # Process submitted message from the form that will be defined later
    if st.session_state.get("submitted_input"):
        user_input = st.session_state.submitted_input
        # Remove the flag and value immediately after retrieving them
        del st.session_state.submitted_input

        if user_input.strip():
            st.session_state.chat_history.append(
                {"role": "user", "content": user_input}
            )
            st.session_state.last_user_input = user_input
            # st.session_state.clear_input = True # No longer needed with the new st.chat_input pattern
            st.rerun()
        # else:
        # st.warning("‚ö†Ô∏è Please enter a message before sending.") # Use st.chat_input, which handles empty messages

    # -------------------------
    # Render chat history
    # -------------------------
    # Use st.container() to hold the chat history
    chat_box_container = st.container()

    with chat_box_container:
        # Loop through and display messages
        for msg in st.session_state.chat_history:
            if msg["role"] == "user":
                with st.chat_message("user"):
                    st.write(msg["content"])
            else:
                with st.chat_message("assistant"):
                    st.write(msg["content"])

        # Placeholder for streaming text. It must be created *before* the input logic for correct placement.
        streaming_placeholder = st.empty()

    # -------------------------
    # Build dataset description for the AI (kept in place)
    # -------------------------
    dataset_description = f"""
You have access to the user's uploaded dataset.

COLUMN NAMES:
{", ".join(df.columns)}

DATA TYPES:
{df.dtypes.to_string()}

SUMMARY STATISTICS:
{df.describe().to_string()}

FIRST 10 ROWS:
{df.head(10).to_string(index=False)}
"""

    # -------------------------
    # Process LLM response (kept in place)
    # -------------------------
    if "last_user_input" in st.session_state:
        user_msg = st.session_state.pop("last_user_input")

        messages_for_api = [
            {
                "role": "system",
                "content": (
                    "You are an expert data analyst specializing in statistics, chemistry, "
                    "machine learning and dataset interpretation.\n"
                    "Use the dataset description below to answer questions accurately, "
                    "identify patterns, recommend preprocessing steps, "
                    "and generate insights.\n\n"
                    f"{dataset_description}"
                ),
            },
            # Append historical chat messages
            *[
                msg
                for msg in st.session_state.chat_history
                if msg["content"]
                != dataset_description  # Avoid including the system prompt description in the history sent to the model repeatedly
            ],
        ]

        try:
            from services import AIService

            ai_service = AIService()
            # client.chat.completions.create is assumed to be available
            stream = ai_service.chat_completion(messages_for_api)

            full_response = ""

            # Streaming response inside the placeholder
            with streaming_placeholder.container():
                text_placeholder = st.empty()

                for chunk in stream:
                    content = chunk.choices[0].delta.content
                    if content:
                        full_response += content
                        text_placeholder.markdown(
                            f"<div style='text-align:left;'>**AI:** {full_response}‚ñå</div>",
                            unsafe_allow_html=True,
                        )

                # Final update
                text_placeholder.markdown(
                    f"<div style='text-align:left;'>**AI:** {full_response}</div>",
                    unsafe_allow_html=True,
                )

                if full_response:
                    st.session_state.chat_history.append(
                        {"role": "assistant", "content": full_response}
                    )

            st.rerun()

        except NameError:
            # Handle case where 'client' is not defined in this snippet (simulating error handling)
            st.error("Groq API client not found (assuming external dependency).")
        except Exception as e:
            st.error(f"API Error: {e}")
            # Remove the last user message if the API call failed
            if (
                st.session_state.chat_history
                and st.session_state.chat_history[-1]["role"] == "user"
            ):
                st.session_state.chat_history.pop()

    user_input = st.chat_input(
        "Pregunta algo sobre el dataset cargado", key="chat_input_box"
    )

    # st.chat_input returns the user's message when submitted.
    if user_input:
        # Save the input to a session state variable to process it at the top of the script
        st.session_state.submitted_input = user_input
        st.rerun()

    # -------------------------


def dashboard_page():
    st.header("üìä Dashboard")

    pca_figs = st.session_state.get("dashboard_pca", [])
    cluster_figs = st.session_state.get("dashboard_cluster", [])
    anova_figs = st.session_state.get("dashboard_anova", [])

    if not pca_figs and not cluster_figs and not anova_figs:
        st.warning("No graphs generated yet. Run analyses to populate the dashboard.")
        return

    palette_options = ["QuimioAnalytics (Custom)", "Viridis", "Plasma", "Inferno"]
    selected_palette = st.selectbox("üé® Color Palette", palette_options, index=0)

    # Get palette
    if selected_palette == "QuimioAnalytics (Custom)":
        palette = ["#B0A461", "#4A525A", "#E0D7B2", "#2E3339", "#8E9E9A"]
    else:
        import plotly.colors

        palette = plotly.colors.sample_colorscale(
            selected_palette.lower(), [i / 9 for i in range(10)]
        )

    # Update colors for all figs
    all_figs = pca_figs + cluster_figs + anova_figs
    for fig in all_figs:
        fig.update_layout(colorway=palette)

    # Select which graphs to display
    st.subheader("Select Graphs to Display")
    col1, col2, col3 = st.columns(3)
    with col1:
        if pca_figs:
            pca_selected = st.multiselect(
                "PCA Graphs",
                [f"PCA Graph {i + 1}" for i in range(len(pca_figs))],
                default=[f"PCA Graph {i + 1}" for i in range(len(pca_figs))],
            )
            pca_indices = [int(s.split()[-1]) - 1 for s in pca_selected]
        else:
            pca_indices = []
    with col2:
        if cluster_figs:
            cluster_selected = st.multiselect(
                "Clustering Graphs",
                [f"Clustering Graph {i + 1}" for i in range(len(cluster_figs))],
                default=[f"Clustering Graph {i + 1}" for i in range(len(cluster_figs))],
            )
            cluster_indices = [int(s.split()[-1]) - 1 for s in cluster_selected]
        else:
            cluster_indices = []
    with col3:
        if anova_figs:
            anova_selected = st.multiselect(
                "ANOVA Graphs",
                [f"ANOVA Graph {i + 1}" for i in range(len(anova_figs))],
                default=[f"ANOVA Graph {i + 1}" for i in range(len(anova_figs))],
            )
            anova_indices = [int(s.split()[-1]) - 1 for s in anova_selected]
        else:
            anova_indices = []

    # Tabs for better visualization
    tab1, tab2, tab3 = st.tabs(
        ["üìà PCA Graphs", "üçá Clustering Graphs", "üßÆ ANOVA Graphs"]
    )

    with tab1:
        if pca_figs and pca_indices:
            for i in pca_indices:
                fig = pca_figs[i]
                st.subheader(f"PCA Graph {i + 1}")
                st.plotly_chart(fig, use_container_width=True, key=f"pca_chart_{i}")
        elif pca_figs:
            st.info("No PCA graphs selected.")
        else:
            st.info("No PCA graphs available.")

    with tab2:
        if cluster_figs and cluster_indices:
            for i in cluster_indices:
                fig = cluster_figs[i]
                st.subheader(f"Clustering Graph {i + 1}")
                st.plotly_chart(fig, use_container_width=True, key=f"cluster_chart_{i}")
        elif cluster_figs:
            st.info("No Clustering graphs selected.")
        else:
            st.info("No Clustering graphs available.")

    with tab3:
        if anova_figs and anova_indices:
            for i in anova_indices:
                fig = anova_figs[i]
                st.subheader(f"ANOVA Graph {i + 1}")
                st.plotly_chart(fig, use_container_width=True, key=f"anova_chart_{i}")
        elif anova_figs:
            st.info("No ANOVA graphs selected.")
        else:
            st.info("No ANOVA graphs available.")

    # Download entire dashboard
    if all_figs:
        from plotly.subplots import make_subplots

        fig_dashboard = make_subplots(
            rows=len(all_figs),
            cols=1,
            subplot_titles=[f"Graph {i + 1}" for i in range(len(all_figs))],
        )
        for i, f in enumerate(all_figs):
            for trace in f.data:
                fig_dashboard.add_trace(trace, row=i + 1, col=1)
        fig_dashboard.update_layout(height=400 * len(all_figs), colorway=palette)

        try:
            import io

            buf = io.BytesIO()
            fig_dashboard.write_image(buf, format="pdf")
            buf.seek(0)
            st.download_button(
                "üì• Download Entire Dashboard as PDF",
                data=buf,
                file_name="dashboard.pdf",
                mime="image/pdf",
            )
        except ValueError:
            st.warning(
                "üì• Download requires 'kaleido' package. Install with: pip install kaleido"
            )
