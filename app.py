import streamlit as st
import time
import base64
import pathlib
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
import statsmodels.api as sm
import plotly.figure_factory as ff
import seaborn as sns
import os

# Import MVCS modules
from models import *
from views import *
from controllers import *
from services import *

# Initialize controllers
session_controller = SessionController()
page_controller = PageController()

# -------------------------
# Initialize Groq client
# -------------------------
from groq import Groq
from dotenv import load_dotenv

load_dotenv()

client = Groq(api_key=os.getenv("GROQ_API_KEY"))

# -------------------------------------------------
# MUST BE FIRST: Page config
# -------------------------------------------------
st.set_page_config(page_title="QuimioAnalytics", page_icon="üß™", layout="wide")

# -------------------------------------------------
# Enhanced Professional CSS
# -------------------------------------------------
professional_css = """
<style>
/* Import Google Fonts */
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

/* Global Styling */
* {
    font-family: 'Inter', sans-serif;
}

/* Main title styling */
h1 {
    color: #B0A461 !important; 
    text-align: center;
    font-weight: 700 !important;
    letter-spacing: -0.5px;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
}

/* Headers styling */
h2 {
    color: #66A3ED !important;
    font-weight: 600 !important;
    border-bottom: 2px solid #B0A461;
    padding-bottom: 8px;
    margin-top: 20px !important;
}

h3 {
    color: #4A525A !important;
    font-weight: 500 !important;
}

/* Sidebar styling */
[data-testid="stSidebar"] {
    background: linear-gradient(180deg, rgba(176, 164, 97, 0.15) 0%, rgba(74, 82, 90, 0.1) 100%);
    backdrop-filter: blur(10px);
}

[data-testid="stSidebar"] button {
    width: 100%;
    margin: 5px 0;
    border-radius: 8px;
    font-weight: 500;
    transition: all 0.3s ease;
}

[data-testid="stSidebar"] button:hover {
    transform: translateX(5px);
    box-shadow: 0 4px 12px rgba(176, 164, 97, 0.3);
}

/* Main content area */
.stApp > div:first-child {
    background: rgba(255, 255, 255, 0.85);
    backdrop-filter: blur(10px);
    border-radius: 15px;
    padding: 20px;
    margin: 20px;
    box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
}

/* Metrics styling */
[data-testid="stMetricValue"] {
    font-size: 2rem !important;
    font-weight: 700 !important;
    color: #B0A461 !important;
}

/* Button styling */
.stButton button {
    background: linear-gradient(135deg, #B0A461 0%, #8E9E9A 100%);
    color: white;
    border: none;
    border-radius: 8px;
    padding: 10px 24px;
    font-weight: 500;
    transition: all 0.3s ease;
}

.stButton button:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(176, 164, 97, 0.4);
}

/* DataFrame styling */
[data-testid="stDataFrame"] {
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.07);
}

/* Info/Warning/Error boxes */
.stAlert {
    border-radius: 10px;
    border-left: 4px solid #B0A461;
}

/* Selectbox and multiselect */
.stSelectbox, .stMultiselect {
    border-radius: 8px;
}

/* File uploader */
[data-testid="stFileUploader"] {
    border: 2px dashed #B0A461;
    border-radius: 10px;
    padding: 20px;
    background: rgba(176, 164, 97, 0.05);
}

/* Tabs styling */
.stTabs [data-baseweb="tab-list"] {
    gap: 8px;
}

.stTabs [data-baseweb="tab"] {
    border-radius: 8px 8px 0 0;
    padding: 10px 20px;
    font-weight: 500;
}

/* Expander styling */
.streamlit-expanderHeader {
    background: rgba(176, 164, 97, 0.1);
    border-radius: 8px;
    font-weight: 500;
}
</style>
"""
st.markdown(professional_css, unsafe_allow_html=True)


# -------------------------------------------------
# Convert image to Base64
# -------------------------------------------------
@st.cache_data
def get_base64_image(image_path):
    try:
        with open(image_path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode()
    except FileNotFoundError:
        return None


IMAGE_FILE_PATH = "background4.jpg"
base64_image = get_base64_image(IMAGE_FILE_PATH)

# -------------------------------------------------
# Background CSS
# -------------------------------------------------
if base64_image:
    mime = "image/" + Path(IMAGE_FILE_PATH).suffix[1:]
    page_bg_img = f"""
    <style>
    .stApp {{
        background-image: url("data:{mime};base64,{base64_image}");
        background-size: cover;
        background-position: center;
        background-attachment: fixed;
    }}
    </style>
    """
else:
    page_bg_img = """
    <style>
    .stApp {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        background-attachment: fixed;
    }
    </style>
    """

st.markdown(page_bg_img, unsafe_allow_html=True)

# -------------------------------------------------
# Auto Snow (run only once)
# -------------------------------------------------
if not st.session_state.snow_triggered:
    st.snow()
    st.session_state.snow_triggered = True

# -------------------------------------------------
# SIDEBAR NAVIGATION
# -------------------------------------------------
with st.sidebar:
    st.markdown("### üß™ QuimioAnalytics")
    st.markdown("---")

    if st.button("üè† Home", use_container_width=True):
        page_controller.set_page("Home")

    if st.button("üìÇ Cargar Dataset", use_container_width=True):
        page_controller.set_page("Cargar dataset")

    if st.button("üîß Preprocesamiento", use_container_width=True):
        page_controller.set_page("Preprocesamiento de Datos")

    if st.button("üìà An√°lisis PCA", use_container_width=True):
        page_controller.set_page("PCA")

    if st.button("üçá Clustering", use_container_width=True):
        page_controller.set_page("Clustering")

    if st.button("üßÆ ANOVA", use_container_width=True):
        page_controller.set_page("ANOVA")

    if st.button("üí¨ AI Chat", use_container_width=True):
        page_controller.set_page("AI Chat")

    st.markdown("---")
    st.markdown("##### üìä Estado del Dataset")
    if st.session_state.df is not None:
        st.success("‚úÖ Dataset cargado")
        st.info(f"üìã {st.session_state.df.shape[0]} filas")
        st.info(f"üìä {st.session_state.df.shape[1]} columnas")
        if st.session_state.get("standardized"):
            st.success("‚úÖ Estandarizado")
    else:
        st.warning("‚ö†Ô∏è Sin dataset")

# -------------------------------------------------
# PAGE CONTROLLER
# -------------------------------------------------
current_page = page_controller.get_current_page()

if current_page == "Home":
    home_page()

elif current_page == "Cargar dataset":
    cargar_dataset()

elif current_page == "Preprocesamiento de Datos":
    preprocessing_page()

elif current_page == "PCA":
    pca_page()

elif current_page == "Clustering":
    cluster_page()

elif current_page == "ANOVA":
    anova_page()

elif current_page == "AI Chat":
    ai_chat_page()
# Initialize Groq client
# -------------------------
client = Groq(api_key=os.getenv("GROQ_API_KEY"))

# -------------------------------------------------
# MUST BE FIRST: Page config
# -------------------------------------------------
st.set_page_config(page_title="QuimioAnalytics", page_icon="üß™", layout="wide")

# -------------------------------------------------
# Initialize session_state variables
# -------------------------------------------------
if "page" not in st.session_state:
    st.session_state.page = "Home"

if "df" not in st.session_state:
    st.session_state.df = None

if "snow_triggered" not in st.session_state:
    st.session_state.snow_triggered = False

if "plot_color_choice" not in st.session_state:
    st.session_state.plot_color_choice = "QuimioAnalytics (Custom)"

# -------------------------------------------------
# Enhanced Professional CSS
# -------------------------------------------------
professional_css = """
<style>
/* Import Google Fonts */
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

/* Global Styling */
* {
    font-family: 'Inter', sans-serif;
}

/* Main title styling */
h1 {
    color: #B0A461 !important; 
    text-align: center;
    font-weight: 700 !important;
    letter-spacing: -0.5px;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
}

/* Headers styling */
h2 {
    color: #66A3ED !important;
    font-weight: 600 !important;
    border-bottom: 2px solid #B0A461;
    padding-bottom: 8px;
    margin-top: 20px !important;
}

h3 {
    color: #4A525A !important;
    font-weight: 500 !important;
}

/* Sidebar styling */
[data-testid="stSidebar"] {
    background: linear-gradient(180deg, rgba(176, 164, 97, 0.15) 0%, rgba(74, 82, 90, 0.1) 100%);
    backdrop-filter: blur(10px);
}

[data-testid="stSidebar"] button {
    width: 100%;
    margin: 5px 0;
    border-radius: 8px;
    font-weight: 500;
    transition: all 0.3s ease;
}

[data-testid="stSidebar"] button:hover {
    transform: translateX(5px);
    box-shadow: 0 4px 12px rgba(176, 164, 97, 0.3);
}

/* Main content area */
.stApp > div:first-child {
    background: rgba(255, 255, 255, 0.85);
    backdrop-filter: blur(10px);
    border-radius: 15px;
    padding: 20px;
    margin: 20px;
    box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
}

/* Metrics styling */
[data-testid="stMetricValue"] {
    font-size: 2rem !important;
    font-weight: 700 !important;
    color: #B0A461 !important;
}

/* Button styling */
.stButton button {
    background: linear-gradient(135deg, #B0A461 0%, #8E9E9A 100%);
    color: white;
    border: none;
    border-radius: 8px;
    padding: 10px 24px;
    font-weight: 500;
    transition: all 0.3s ease;
}

.stButton button:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 20px rgba(176, 164, 97, 0.4);
}

/* DataFrame styling */
[data-testid="stDataFrame"] {
    border-radius: 10px;
    overflow: hidden;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.07);
}

/* Info/Warning/Error boxes */
.stAlert {
    border-radius: 10px;
    border-left: 4px solid #B0A461;
}

/* Selectbox and multiselect */
.stSelectbox, .stMultiselect {
    border-radius: 8px;
}

/* File uploader */
[data-testid="stFileUploader"] {
    border: 2px dashed #B0A461;
    border-radius: 10px;
    padding: 20px;
    background: rgba(176, 164, 97, 0.05);
}

/* Tabs styling */
.stTabs [data-baseweb="tab-list"] {
    gap: 8px;
}

.stTabs [data-baseweb="tab"] {
    border-radius: 8px 8px 0 0;
    padding: 10px 20px;
    font-weight: 500;
}

/* Expander styling */
.streamlit-expanderHeader {
    background: rgba(176, 164, 97, 0.1);
    border-radius: 8px;
    font-weight: 500;
}
</style>
"""
st.markdown(professional_css, unsafe_allow_html=True)


# -------------------------------------------------
# Convert image to Base64
# -------------------------------------------------
@st.cache_data
def get_base64_image(image_path):
    try:
        with open(image_path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode()
    except FileNotFoundError:
        return None


IMAGE_FILE_PATH = "background4.jpg"
base64_image = get_base64_image(IMAGE_FILE_PATH)

# -------------------------------------------------
# Background CSS
# -------------------------------------------------
if base64_image:
    mime = "image/" + Path(IMAGE_FILE_PATH).suffix[1:]
    page_bg_img = f"""
    <style>
    .stApp {{
        background-image: url("data:{mime};base64,{base64_image}");
        background-size: cover;
        background-position: center;
        background-attachment: fixed;
    }}
    </style>
    """
else:
    page_bg_img = """
    <style>
    .stApp {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        background-attachment: fixed;
    }
    </style>
    """

st.markdown(page_bg_img, unsafe_allow_html=True)

# -------------------------------------------------
# Auto Snow (run only once)
# -------------------------------------------------
if not st.session_state.snow_triggered:
    st.snow()
    st.session_state.snow_triggered = True


# -------------------------------------------------
# HOME PAGE
# -------------------------------------------------
def home_page():
    st.title("QuimioAnalytics")

    # Define the text for the speech bubble (Using Spanish greeting from your source)
    ASSISTANT_GREETING = "Hola, mi nombre es Heisenberg y soy tu assistente virtual. Carga tu dataset y puedo ayudarte üôÇ"

    # ---------- Read local image and convert to base64 ----------
    # NOTE: This part assumes 'man.png' exists in the same directory where the script is run.
    img_path = pathlib.Path("man.png")
    img_data_uri = None
    try:
        with img_path.open("rb") as f:
            data = f.read()
            b64 = base64.b64encode(data).decode("utf-8")
            img_data_uri = f"data:image/png;base64,{b64}"
    except Exception as e:
        # If reading fails, fall back to a simple st.image (so user still sees something)
        st.warning(
            f"Could not embed man.png as data URI ({e}). Falling back to st.image below."
        )

    # ---------- CSS for positioning the floating image AND the speech bubble ----------
    # The image is now just a static floating element.
    st.markdown(
        f"""
    <style>
    /* ensures the floating image sits above other content and doesn't affect layout */
    .floating-image-container {{
        position: fixed;
        top: 250px;      /* Vertical position */
        right: 18px;    /* distance from right edge */
        width: 160px;   /* max width of the container */
        z-index: 9999;
        text-align: center;
        /* cursor: pointer; -- REMOVED */
    }}
    
    /* Ensure the link wrapper takes up the whole container area and removes link styles */
    /* .floating-link is no longer used, CSS kept for robustness */
    .floating-link {{
        display: block;
        color: inherit;
        text-decoration: none;
    }}

    .floating-image-container img {{
        width: 100%;
        height: auto;
        border-radius: 0px;
        box-shadow: 0 0px 0px rgba(0,0,0,0);
        display: block;
        margin: 0;
    }}

    /* Speech Bubble Styles */
    .speech-bubble {{
        background: #eef4ff; /* Light blue/grey for a modern look */
        color: #333333;
        padding: 10px 15px;
        border-radius: 15px;
        margin-bottom: 8px; /* Space between bubble and image */
        position: relative;
        font-size: 13px; /* Slightly smaller text for the bubble */
        text-align: left;
        box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        line-height: 1.4;
    }}

    /* Speech bubble tail (points down to the image) */
    .speech-bubble::after {{
        content: '';
        position: absolute;
        bottom: -10px; /* Position below the bubble */
        left: 50%;
        transform: translateX(-50%);
        width: 0;
        height: 0;
        border-left: 10px solid transparent;
        border-right: 10px solid transparent;
        border-top: 10px solid #eef4ff; /* Match bubble background color */
    }}

    /* Add a subtle hover effect to indicate clickability */
    .floating-image-container:hover {{
        /* REMOVED hover effect */
        /* transition: transform 0.2s ease-in-out; */
    }}
    </style>
    """,
        unsafe_allow_html=True,
    )

    # ---------- WELCOME CARD (unchanged from your source) ----------
    st.markdown(
        """
    <div style='
        background-color: #ffffff;
        padding: 30px;
        border-radius: 15px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        text-align: center;
        max-width: 650px;
        margin-left: auto;
        margin-right: auto;
    '>
        <h2 style='margin-bottom: 10px;'>Bienvenido a QuimioAnalytics</h2>
        <p style='font-size: 16px; color: #444;'>
            Esta plataforma est√° dise√±ada especialmente para <strong>estudiantes de qu√≠mica</strong> 
            que desean explorar y analizar datos de manera intuitiva, sin necesidad de programar.
        </p>
        <p style='font-size: 1rem; color: #666; margin-top: 20px;'>
            Utiliza el panel lateral para navegar entre las diferentes herramientas de an√°lisis.
        </p>
    </div>
    """,
        unsafe_allow_html=True,
    )

    # ---------- Insert floating image (data URI) or fallback (STATIC) ----------
    if img_data_uri:
        # RENDERED WITHOUT THE <a> TAG WRAPPER
        html = f"""
            <div class="floating-image-container">
                <div class="speech-bubble">
                    {ASSISTANT_GREETING}
                </div>
                <img src="{img_data_uri}" alt="Heisenberg">
            </div>
        """
        st.markdown(html, unsafe_allow_html=True)
    else:
        # fallback: use st.image (will occupy a normal Streamlit spot but only shown if embedding failed)
        st.image("man.png", caption=ASSISTANT_GREETING, width=140)

    st.markdown("---")

    # Tabs for organization
    tab1, tab2, tab3 = st.tabs(
        ["Introducci√≥n", "Fundamentos Te√≥ricos", "Ejemplo Guiado"]
    )

    with tab1:
        st.markdown("### Herramientas Disponibles")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.markdown(
                """
            <div style='padding: 20px; background: rgba(176,164,97,0.1); border-radius: 10px; text-align: center;'>
                <h3>Carga de Datos</h3>
                <p>CSV y Excel</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        with col2:
            st.markdown(
                """
            <div style='padding: 20px; background: rgba(153,191,240,0.1); border-radius: 10px; text-align: center;'>
                <h3>Preprocesamiento</h3>
                <p>Limpieza y escalado</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        with col3:
            st.markdown(
                """
            <div style='padding: 20px; background: rgba(176,164,97,0.1); border-radius: 10px; text-align: center;'>
                <h3>An√°lisis PCA</h3>
                <p>Reducci√≥n de dimensiones</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

        with col4:
            st.markdown(
                """
            <div style='padding: 20px; background: rgba(153,191,240,0.1); border-radius: 10px; text-align: center;'>
                <h3>ANOVA</h3>
                <p>Comparaci√≥n de grupos</p>
            </div>
            """,
                unsafe_allow_html=True,
            )

    with tab2:
        st.markdown("### Fundamentos de Quimiometr√≠a")

        with st.expander("Importancia del An√°lisis Multivariante", expanded=False):
            st.markdown("""
            El an√°lisis multivariante es fundamental en qu√≠mica anal√≠tica moderna porque permite:
            
            - Trabajar simult√°neamente con m√∫ltiples variables qu√≠micas (se√±ales espectrales, concentraciones, intensidades)
            - Identificar patrones ocultos en datos complejos
            - Reducir la dimensionalidad preservando informaci√≥n qu√≠mica relevante
            - Clasificar muestras seg√∫n su composici√≥n qu√≠mica
            - Detectar correlaciones entre variables que no son evidentes en an√°lisis univariados
            """)

        with st.expander("Estandarizaci√≥n de Datos", expanded=False):
            st.markdown("""
            ### ¬øPor qu√© estandarizar?
            
            La estandarizaci√≥n transforma las variables para que tengan media cero y desviaci√≥n est√°ndar uno.
            
            #### Para el ANOVA
            
            Aunque no es estrictamente necesario para ANOVA simple, la estandarizaci√≥n es importante cuando:
            
            - **Comparabilidad entre variables:** Permite comparar la magnitud del efecto cuando se usan m√∫ltiples variables en escalas diferentes
            - **Homogeneidad de varianzas:** Puede ayudar a estabilizar varianzas cuando los grupos tienen desviaciones est√°ndar desiguales
            - **Interpretaci√≥n de coeficientes:** Facilita la comparaci√≥n en modelos de regresi√≥n subyacentes
            - **M√©todos avanzados:** Es fundamental para PCA y an√°lisis de clusters
            
            #### Para el PCA
            
            **La estandarizaci√≥n es esencial para PCA.** Si las variables no se estandarizan y una tiene varianza mucho mayor, 
            esa variable controlar√° la primera componente principal. La estandarizaci√≥n evita esto haciendo que todas las 
            variables tengan el mismo peso.
            
            En t√©rminos matem√°ticos, las componentes principales son los autovectores de la matriz de correlaci√≥n. 
            Para datos estandarizados, cada variable original tiene varianza de 1, por lo que la varianza total 
            del conjunto de datos y la suma de los autovalores son ambos iguales al n√∫mero de variables.
            
            #### Para An√°lisis de Clusters
            
            **La estandarizaci√≥n es altamente recomendada** porque la mayor√≠a de algoritmos (k-means, clustering jer√°rquico) 
            se basan en medidas de distancia sensibles a la magnitud de cada variable.
            
            Desde el punto de vista te√≥rico, la distancia Euclidiana se define como la suma de diferencias al cuadrado 
            entre variables. Una variable con escala grande domina la contribuci√≥n total de la distancia y determina 
            artificialmente la formaci√≥n de clusters. Al estandarizar, todas las variables tienen influencia equilibrada.
            """)

        with st.expander("An√°lisis de Varianza (ANOVA)", expanded=False):
            st.markdown("""
            ### ¬øQu√© es el ANOVA?
            
            El **An√°lisis de la Varianza** es una t√©cnica estad√≠stica para separar y estimar diferentes causas de variaci√≥n.
            
            **Funci√≥n principal:** Evaluar si las variaciones en la respuesta qu√≠mica (se√±ales espectrosc√≥picas, concentraciones, 
            absorbancias, intensidades) se deben realmente a factores experimentales y no al azar.
            
            ### Importancia en Quimiometr√≠a
            
            En quimiometr√≠a, el ANOVA es fundamental porque:
            
            1. **Identifica variables discriminantes:** Determina qu√© variables qu√≠micas realmente diferencian los grupos
            2. **Valida diferencias qu√≠micas:** Confirma que hay verdaderas diferencias antes del an√°lisis multivariado
            3. **Interpretaci√≥n univariada:** Relaciona directamente variables individuales (picos FAME) con fen√≥menos qu√≠micos
            4. **Detecta se√±ales responsables:** Identifica qu√© se√±ales qu√≠micas causan la variaci√≥n en PCA
            
            ### Ecuaciones Fundamentales
            
            **Suma de cuadrados total (SST):** Variabilidad total en los datos
            $SS_T = \\sum_{i=1}^{k}\\sum_{j=1}^{n_i} (y_{ij} - \\bar{y})^2$
            
            **Suma de cuadrados entre grupos (SSB):** Variabilidad explicada por diferencias entre grupos
            $SS_A = \\sum_{i=1}^{k} n_i (\\bar{y}_i - \\bar{y})^2$
            
            **Suma de cuadrados dentro de grupos (SSE):** Variabilidad interna (error o ruido)
            $SS_E = \\sum_{i=1}^{k}\\sum_{j=1}^{n_i} (y_{ij} - \\bar{y}_i)^2$
            
            **Estad√≠stico F:** Compara variabilidad explicada vs no explicada
            $F = \\frac{MS_A}{MS_E}$
            
            ### Interpretaci√≥n
            
            - **F grande:** Las diferencias entre grupos son mayores que la variabilidad aleatoria
            - **p-valor < 0.05:** Rechazamos la hip√≥tesis nula, hay diferencias significativas
            - **p-valor ‚â• 0.05:** No hay evidencia suficiente de diferencias significativas
            """)

        with st.expander("An√°lisis de Componentes Principales (PCA)", expanded=False):
            st.markdown("""
            ### ¬øQu√© es el PCA?
            
            Es una t√©cnica para **reducir la dimensionalidad** cuando existe correlaci√≥n entre variables.
            
            La idea es encontrar componentes principales Z‚ÇÅ, Z‚ÇÇ, ..., Z‚Çô que sean combinaciones lineales 
            de las variables originales X‚ÇÅ, X‚ÇÇ, ..., X‚Çô:
            
            $Z_1 = a_{11}X_1 + a_{12}X_2 + a_{13}X_3 + \\dots + a_{1n}X_n$
            
            Los coeficientes se eligen para que:
            1. Las nuevas variables no est√©n correlacionadas entre s√≠
            2. La primera componente (PC1) capture la mayor variaci√≥n
            3. La segunda (PC2) capture la siguiente mayor variaci√≥n, y as√≠ sucesivamente
            
            ### Importancia en Quimiometr√≠a
            
            PCA es central en quimiometr√≠a para explorar mezclas qu√≠micas y se√±ales multivariadas. Permite detectar:
            
            - **Agrupamientos** en los datos
            - **Variables responsables** de la diferenciaci√≥n
            - **Outliers** experimentales o qu√≠micos
            - **Relaciones entre picos** (covarianzas qu√≠micas)
            
            Los **loadings** muestran c√≥mo cada variable contribuye qu√≠micamente a las componentes principales.
            
            ### Visualizaciones Clave
            
            **Scree Plot:** Muestra varianza explicada por cada componente. La varianza explicada por el componente i es:
            $\\frac{\\lambda_i}{\\sum_{j=1}^{n} \\lambda_j}$
            
            Ayuda a decidir cu√°ntos componentes son necesarios para describir la estructura qu√≠mica.
            
            **Scores Plot:** Distribuci√≥n de muestras en el espacio de componentes principales. Muestras cercanas 
            tienen patrones similares (composiciones qu√≠micas parecidas).
            
            **Loadings Plot:** Muestra contribuci√≥n de cada variable a los componentes. Los loadings son elementos 
            de los vectores propios. Mayor valor absoluto indica mayor influencia.
            
            **Biplot:** Combina scores y loadings en una sola gr√°fica, permitiendo relacionar directamente 
            caracter√≠sticas qu√≠micas con patrones observados.
            """)

        with st.expander("An√°lisis de Clusters", expanded=False):
            st.markdown("""
            ### ¬øQu√© es el An√°lisis de Clusters?
            
            Es un m√©todo para **dividir objetos en clases** de manera que objetos similares queden en la misma clase.
            
            Como en PCA, los grupos no se conocen antes del an√°lisis. Busca objetos pr√≥ximos en el espacio de variables.
            
            **Distancia Euclidiana:**
            $d = \\sqrt{\\sum_{i=1}^n (x_i-y_i)^2}$
            
            **Distancia Manhattan:**
            $D_{Manhattan} = |x_1 - x_2| + |y_1 - y_2|$
            
            ### Importancia en Quimiometr√≠a
            
            El clustering es fundamental porque permite:
            
            - **Identificar patrones naturales** sin categor√≠as predefinidas
            - **Agrupar muestras** seg√∫n similitud qu√≠mica
            - **Detectar relaciones** no evidentes a simple vista
            - **Distinguir feedstocks** e identificar adulteraciones
            - **Evaluar calidad** de lotes y procesos
            - **Complementar PCA** asignando grupos en el espacio reducido
            - **Detectar outliers** (errores instrumentales o contaminaci√≥n)
            
            ### Visualizaciones
            
            **Dendrograma:** Muestra c√≥mo las muestras se agrupan jer√°rquicamente. La altura de uni√≥n indica 
            la diferencia qu√≠mica. Un corte horizontal permite decidir el n√∫mero de clusters.
            
            **Scatter Plot en espacio PCA:** Proyecta clusters en PC1 vs PC2, mostrando separaci√≥n espacial 
            y consistencia con la estructura qu√≠mica.
            
            ### M√©trica de Calidad: √çndice Silhouette
            
            Eval√∫a cu√°n bien definidas est√°n las clases obtenidas. Mide:
            - Separaci√≥n qu√≠mica entre grupos
            - Coherencia interna de cada grupo
            - Validaci√≥n de que las diferencias son qu√≠micamente reales
            """)

    with tab3:
        st.markdown("### Ejemplo: An√°lisis de Datos Espectrales")

        st.markdown("""
        A continuaci√≥n se presenta un flujo de trabajo t√≠pico para an√°lisis quimiom√©trico de datos espectrales:
        """)

        st.markdown("#### Paso 1: Carga de Datos")
        st.info("""
        **Acci√≥n:** Navega a "Cargar Dataset" en el panel lateral.
        
        - Sube un archivo CSV o Excel con tus datos espectrales
        - Las filas representan muestras individuales
        - Las columnas representan variables qu√≠micas (longitudes de onda, picos FAME, concentraciones)
        - Aseg√∫rate de incluir al menos una columna categ√≥rica (ej: tipo de feedstock, lote, concentraci√≥n)
        """)

        st.markdown("#### Paso 2: Preprocesamiento")
        st.info("""
        **Acci√≥n:** Ve a "Preprocesamiento de Datos"
        
        1. **Limpieza de valores nulos:** Elimina filas con datos faltantes
        2. **Eliminaci√≥n de columnas:** Remueve variables no relevantes (ej: identificadores, fechas)
        3. **Estandarizaci√≥n:** Aplica transformaci√≥n Z-score a variables num√©ricas
        
        **Importante:** La estandarizaci√≥n es esencial antes de PCA y clustering.
        """)

        st.markdown("#### Paso 3: An√°lisis ANOVA")
        st.info("""
        **Acci√≥n:** Selecciona "ANOVA" en el panel lateral
        
        - **Variable Dependiente:** Elige una variable qu√≠mica num√©rica (ej: intensidad de pico)
        - **Variable Factor:** Selecciona la variable categ√≥rica (ej: tipo de feedstock)
        - **Interpretaci√≥n:**
          - Si p < 0.05: Existen diferencias significativas entre grupos
          - Revisa el Test de Tukey para identificar qu√© pares de grupos difieren
          - Observa los box plots y violin plots para entender la distribuci√≥n
        """)

        st.markdown("#### Paso 4: An√°lisis PCA")
        st.info("""
        **Acci√≥n:** Navega a "An√°lisis PCA"
        
        1. **Selecci√≥n de variables:** Elige las columnas num√©ricas relevantes
        2. **Scree Plot:** Determina cu√°ntos componentes capturan la varianza (usualmente 2-3 para >80%)
        3. **Scores Plot:** 
           - Selecciona qu√© componentes visualizar (PC1 vs PC2, PC1 vs PC3, etc.)
           - Identifica agrupamientos de muestras similares
           - Detecta outliers (puntos muy alejados)
        4. **Loadings:** Identifica qu√© variables contribuyen m√°s a cada componente
        5. **Biplot:** Relaciona variables con la separaci√≥n de muestras
        
        **Personalizaci√≥n disponible:**
        - Cambiar paleta de colores
        - Seleccionar diferentes pares de componentes
        - Colorear por feedstock o concentraci√≥n
        """)

        st.markdown("#### Paso 5: Interpretaci√≥n Qu√≠mica")
        st.success("""
        **Integra los resultados:**
        
        - **ANOVA:** Confirma qu√© variables diferencian significativamente los grupos
        - **PCA:** Visualiza la estructura multivariada y detecta patrones
        - **Loadings:** Identifica qu√© picos o se√±ales causan la separaci√≥n
        - **Consistencia:** Verifica que los grupos en PCA correspondan con diferencias significativas en ANOVA
        
        **Ejemplo de conclusi√≥n qu√≠mica:**
        "Las muestras de feedstock A y B se separan claramente en PC1 (65% varianza), 
        principalmente debido a diferencias en las variables X1 y X5 (loadings altos). 
        El ANOVA confirma que estas diferencias son estad√≠sticamente significativas (p < 0.001)."
        """)

        st.markdown("---")
        st.markdown("#### Dataset de Ejemplo")

        # Create example dataset
        np.random.seed(42)
        n_samples = 30

        example_data = {
            "Feedstock": ["Tipo_A"] * 10 + ["Tipo_B"] * 10 + ["Tipo_C"] * 10,
            "Peak_280nm": np.concatenate(
                [
                    np.random.normal(15, 2, 10),
                    np.random.normal(25, 2, 10),
                    np.random.normal(20, 2, 10),
                ]
            ),
            "Peak_320nm": np.concatenate(
                [
                    np.random.normal(30, 3, 10),
                    np.random.normal(35, 3, 10),
                    np.random.normal(40, 3, 10),
                ]
            ),
            "Peak_450nm": np.concatenate(
                [
                    np.random.normal(50, 4, 10),
                    np.random.normal(45, 4, 10),
                    np.random.normal(55, 4, 10),
                ]
            ),
            "Peak_600nm": np.concatenate(
                [
                    np.random.normal(20, 2, 10),
                    np.random.normal(30, 2, 10),
                    np.random.normal(25, 2, 10),
                ]
            ),
        }

        example_df = pd.DataFrame(example_data)

        st.markdown("**Descarga este dataset de ejemplo para practicar:**")
        st.dataframe(example_df.head(10), use_container_width=True)

        csv_example = example_df.to_csv(index=False)
        st.download_button(
            label="Descargar Dataset de Ejemplo (CSV)",
            data=csv_example,
            file_name="ejemplo_espectros.csv",
            mime="text/csv",
        )


# -------------------------------------------------
# CARGAR DATASET
# -------------------------------------------------
def cargar_dataset():
    st.header("üìÇ Cargar Dataset")

    uploaded_file = st.file_uploader(
        "Arrastra o selecciona tu archivo CSV o Excel",
        type=["csv", "xlsx", "xls"],
        help="Formatos soportados: CSV, XLSX, XLS",
    )

    if uploaded_file:
        df = None

        with st.spinner("Cargando archivo..."):
            if uploaded_file.name.endswith(".csv"):
                try:
                    df = pd.read_csv(uploaded_file)
                except Exception as e:
                    st.error(f"‚ùå Error leyendo archivo CSV: {e}")

            elif uploaded_file.name.endswith((".xlsx", ".xls")):
                try:
                    df = pd.read_excel(uploaded_file)
                except Exception as e:
                    st.error(f"‚ùå Error leyendo archivo Excel: {e}")

        if df is not None:
            st.session_state.df = df
            st.success("‚úÖ ¬°Archivo cargado exitosamente!")

            # Dataset overview
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üìã Filas", df.shape[0])
            with col2:
                st.metric("üìä Columnas", df.shape[1])
            with col3:
                st.metric(
                    "üíæ Tama√±o", f"{df.memory_usage(deep=True).sum() / 1024:.1f} KB"
                )

            st.markdown("### üëÅÔ∏è Vista Previa de los Datos")
            st.dataframe(df.head(10), use_container_width=True)

            # Statistical summary
            st.markdown("## üìä Resumen Estad√≠stico B√°sico")

            numeric_df = df.select_dtypes(include=["number"])

            if numeric_df.empty:
                st.warning(
                    "‚ö†Ô∏è El dataset no contiene columnas num√©ricas para calcular estad√≠sticas."
                )
            else:
                tab1, tab2 = st.tabs(["üìå Tendencia Central", "üìê Dispersi√≥n"])

                with tab1:
                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.markdown("**üìç Media**")
                        st.dataframe(numeric_df.mean(), use_container_width=True)

                    with col2:
                        st.markdown("**üéØ Mediana**")
                        st.dataframe(numeric_df.median(), use_container_width=True)

                    with col3:
                        st.markdown("**üî¢ Moda**")
                        st.dataframe(
                            numeric_df.mode().iloc[0], use_container_width=True
                        )

                with tab2:
                    col1, col2 = st.columns(2)

                    with col1:
                        st.markdown("**üìè Rango**")
                        st.dataframe(
                            numeric_df.max() - numeric_df.min(),
                            use_container_width=True,
                        )

                        st.markdown("**üìä Desviaci√≥n Est√°ndar**")
                        st.dataframe(numeric_df.std(), use_container_width=True)

                    with col2:
                        st.markdown("**üìà Varianza**")
                        st.dataframe(numeric_df.var(), use_container_width=True)

                        st.markdown("**üì¶ Rango Intercuart√≠lico (IQR)**")
                        st.dataframe(
                            numeric_df.quantile(0.75) - numeric_df.quantile(0.25),
                            use_container_width=True,
                        )

            st.markdown("---")

            col1, col2, col3 = st.columns([1, 1, 1])
            with col2:
                if st.button(
                    "‚û°Ô∏è Ir a Preprocesamiento de Datos",
                    type="primary",
                    use_container_width=True,
                ):
                    st.session_state.page = "Preprocesamiento de Datos"
                    st.rerun()


# -------------------------------------------------
# PREPROCESSING PAGE
# -------------------------------------------------
def preprocessing_page():
    st.header("üîß Preprocesamiento de Datos")

    if st.session_state.df is None:
        st.warning("‚ö†Ô∏è A√∫n no has cargado un dataset.")
        if st.button("‚¨ÖÔ∏è Regresar a cargar dataset"):
            st.session_state.page = "Cargar dataset"
            st.rerun()
        return

    df_current = st.session_state.df.copy()
    current_rows, current_cols = df_current.shape

    col1, col2 = st.columns(2)
    with col1:
        st.metric("üìã Filas actuales", current_rows)
    with col2:
        st.metric("üìä Columnas actuales", current_cols)

    st.dataframe(df_current.head(), use_container_width=True)

    st.markdown("---")

    # Limpieza NaN
    with st.expander("üßπ Limpieza de Valores Nulos (NaN)", expanded=True):
        initial_nan = df_current.isnull().any(axis=1).sum()
        st.metric("Filas con valores nulos", initial_nan)

        if st.button("üóëÔ∏è Eliminar filas con NaN", key="clean_btn"):
            df_clean = df_current.dropna()
            dropped = df_current.shape[0] - df_clean.shape[0]
            st.session_state.df = df_clean
            st.success(f"‚úÖ Se eliminaron **{dropped}** filas.")
            st.rerun()

    # Eliminaci√≥n de Columnas
    with st.expander("‚ùå Eliminaci√≥n de Columnas"):
        st.write("Selecciona las columnas que deseas eliminar:")

        cols_to_display = list(df_current.columns)
        cols_per_row = 4

        for i in range(0, len(cols_to_display), cols_per_row):
            cols = st.columns(cols_per_row)
            for j, column in enumerate(cols_to_display[i : i + cols_per_row]):
                with cols[j]:
                    if st.button(f"‚ùå {column}", key=f"drop_{column}"):
                        df_updated = df_current.drop(columns=[column])
                        st.session_state.df = df_updated
                        st.success(f"Columna '{column}' eliminada.")
                        st.rerun()

    # Estandarizaci√≥n
    with st.expander("üìè Estandarizaci√≥n (Z-Score)", expanded=True):
        numerical_cols = df_current.select_dtypes(include=[np.number]).columns.tolist()

        if not numerical_cols:
            st.warning("‚ö†Ô∏è No hay columnas num√©ricas disponibles.")
        else:
            st.info(f"**Columnas num√©ricas detectadas:** {', '.join(numerical_cols)}")

            if st.button(
                "‚ö° Estandarizar Columnas Num√©ricas",
                key="standardize_btn",
                type="primary",
            ):
                try:
                    # Hacer una copia para no modificar el original
                    df_to_standardize = df_current.copy()

                    # Reemplazar infinitos y eliminar NaNs
                    df_to_standardize.replace([np.inf, -np.inf], np.nan, inplace=True)
                    df_to_standardize.dropna(subset=numerical_cols, inplace=True)

                    # Estandarizar solo las columnas num√©ricas
                    scaler = StandardScaler()
                    df_to_standardize[numerical_cols] = scaler.fit_transform(
                        df_to_standardize[numerical_cols]
                    )

                    # Guardar el dataframe estandarizado
                    st.session_state.df = df_to_standardize
                    st.session_state.standardized = True
                    st.success("‚úÖ ¬°Estandarizaci√≥n completada!")
                    time.sleep(0.5)
                    st.rerun()

                except Exception as e:
                    st.error(f"‚ùå Error durante estandarizaci√≥n: {e}")
                    st.error(f"Detalles: {str(e)}")

    if st.session_state.get("standardized"):
        st.success("‚úÖ El dataset ya fue estandarizado.")

        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            if st.button(
                "‚û°Ô∏è Ir a An√°lisis PCA", type="primary", use_container_width=True
            ):
                st.session_state.page = "PCA"
                st.rerun()


# -------------------------------------------------
# PCA PAGE (ENHANCED)
# -------------------------------------------------
def pca_page():
    st.header("üìà An√°lisis de Componentes Principales (PCA)")

    with st.expander("‚ÑπÔ∏è ¬øQu√© es el PCA?", expanded=False):
        st.markdown("""
        El **An√°lisis de Componentes Principales (PCA)** es una t√©cnica de reducci√≥n de dimensionalidad que:
        
        - üéØ Transforma variables correlacionadas en componentes independientes
        - üìä Captura la mayor varianza posible en menos dimensiones
        - üîç Facilita la visualizaci√≥n de datos multidimensionales
        - ‚ö° Mejora el rendimiento de modelos de machine learning
        
        **Importante:** Los datos deben estar estandarizados antes de aplicar PCA.
        """)

    COLOR_PALETTES = {
        "QuimioAnalytics (Custom)": [
            "#B0A461",
            "#4A525A",
            "#E0D7B2",
            "#2E3339",
            "#8E9E9A",
        ],
        "Viridis (Default)": "viridis",
        "Plasma": "plasma",
        "Cividis": "cividis",
        "Inferno": "inferno",
        "Magma": "magma",
        "Cool Warm": ["#0000FF", "#87CEEB", "#FFFFFF", "#FF6347", "#FF0000"],
        "Greyscale": ["#000000", "#555555", "#AAAAAA", "#CCCCCC", "#FFFFFF"],
    }

    if st.session_state.df is None:
        st.warning("‚ö†Ô∏è Carga un dataset primero.")
        return

    df_pca = st.session_state.df.copy()
    numeric_cols = df_pca.select_dtypes(include=[np.number]).columns.tolist()

    if not numeric_cols:
        st.error("‚ùå No hay columnas num√©ricas en el dataset.")
        return

    if not st.session_state.get("standardized", False):
        st.warning("‚ö†Ô∏è Debes estandarizar los datos antes de realizar PCA.")
        return

    col1, col2 = st.columns([2, 1])

    with col1:
        selected_columns = st.multiselect(
            "üéØ Selecciona columnas num√©ricas para PCA:",
            numeric_cols,
            default=numeric_cols,
        )

    with col2:
        st.session_state.plot_color_choice = st.selectbox(
            "üé® Paleta de colores:",
            list(COLOR_PALETTES.keys()),
            index=list(COLOR_PALETTES.keys()).index(st.session_state.plot_color_choice),
        )

    if len(selected_columns) < 2:
        st.warning("‚ö†Ô∏è Selecciona al menos 2 columnas para aplicar PCA.")
        return

    if st.button("‚ñ∂Ô∏è Aplicar PCA", key="run_pca", type="primary"):
        st.session_state.pca_ready = True
        st.session_state.pca_columns = selected_columns
        st.rerun()

    if st.session_state.get("pca_ready", False):
        columns = st.session_state.get("pca_columns", selected_columns)
        X = df_pca[columns].values
        n_components = min(X.shape)

        pca = PCA(n_components=n_components)
        pc_values = pca.fit_transform(X)

        explained = pca.explained_variance_ratio_
        cumulative = np.cumsum(explained)

        st.success("‚úÖ PCA aplicado correctamente")

        # Tabs for different analyses
        tab1, tab2, tab3, tab4, tab5 = st.tabs(
            [
                "üìä Varianza Explicada",
                "üéØ Gr√°fico de Componentes",
                "üîó Biplot",
                "üîç Loadings",
                "üìã Datos Transformados",
            ]
        )

        with tab1:
            st.subheader("Scree Plot - Varianza Explicada")

            df_var = pd.DataFrame(
                {
                    "Componente": [f"PC{i + 1}" for i in range(n_components)],
                    "Varianza (%)": explained * 100,
                    "Acumulada (%)": cumulative * 100,
                }
            )

            palette = COLOR_PALETTES[st.session_state.plot_color_choice]

            fig = go.Figure()

            fig.add_trace(
                go.Bar(
                    x=df_var["Componente"],
                    y=df_var["Varianza (%)"],
                    name="Varianza Individual",
                    marker_color="#B0A461",
                )
            )

            fig.add_trace(
                go.Scatter(
                    x=df_var["Componente"],
                    y=df_var["Acumulada (%)"],
                    mode="lines+markers",
                    name="Varianza Acumulada",
                    line=dict(color="#4A525A", width=3),
                    marker=dict(size=10),
                )
            )

            fig.update_layout(
                title="Varianza Explicada por Componente Principal",
                xaxis_title="Componente",
                yaxis_title="Varianza (%)",
                hovermode="x unified",
                template="plotly_white",
            )

            st.plotly_chart(fig, use_container_width=True)

            st.dataframe(df_var, use_container_width=True)

        with tab2:
            st.subheader("Visualizaci√≥n de Componentes Principales")

            if n_components >= 2:
                col1, col2 = st.columns(2)

                with col1:
                    pc_x = st.selectbox(
                        "Componente X:",
                        [f"PC{i + 1}" for i in range(n_components)],
                        index=0,
                    )

                with col2:
                    pc_y = st.selectbox(
                        "Componente Y:",
                        [f"PC{i + 1}" for i in range(n_components)],
                        index=1,
                    )

                pc_x_idx = int(pc_x.replace("PC", "")) - 1
                pc_y_idx = int(pc_y.replace("PC", "")) - 1

                df_plot = pd.DataFrame(
                    pc_values[:, [pc_x_idx, pc_y_idx]], columns=[pc_x, pc_y]
                )
                df_plot["ID"] = df_pca.index.astype(str)

                fig_scatter = px.scatter(
                    df_plot,
                    x=pc_x,
                    y=pc_y,
                    color="ID",
                    title=f"PCA: {pc_x} vs {pc_y}",
                    color_discrete_sequence=palette
                    if isinstance(palette, list)
                    else None,
                )

                fig_scatter.update_traces(
                    marker=dict(size=10, line=dict(width=1, color="white"))
                )
                fig_scatter.update_layout(template="plotly_white")

                st.plotly_chart(fig_scatter, use_container_width=True)

                col1, col2 = st.columns(2)
                with col1:
                    st.metric(f"Varianza {pc_x}", f"{explained[pc_x_idx] * 100:.2f}%")
                with col2:
                    st.metric(f"Varianza {pc_y}", f"{explained[pc_y_idx] * 100:.2f}%")

        with tab3:
            st.subheader("Biplot - Scores y Loadings Combinados")

            st.markdown("""
            El **biplot** combina las puntuaciones (scores) de las muestras con las cargas (loadings) de las variables.
            Permite identificar qu√© variables son responsables de las agrupaciones observadas en las muestras.
            """)

            if n_components >= 2:
                col1, col2 = st.columns(2)

                with col1:
                    pc_x_bi = st.selectbox(
                        "Componente X:",
                        [f"PC{i + 1}" for i in range(n_components)],
                        index=0,
                        key="biplot_x",
                    )

                with col2:
                    pc_y_bi = st.selectbox(
                        "Componente Y:",
                        [f"PC{i + 1}" for i in range(n_components)],
                        index=1,
                        key="biplot_y",
                    )

                pc_x_idx_bi = int(pc_x_bi.replace("PC", "")) - 1
                pc_y_idx_bi = int(pc_y_bi.replace("PC", "")) - 1

                # Create biplot
                fig_biplot = go.Figure()

                # Add scores (samples)
                scores_x = pc_values[:, pc_x_idx_bi]
                scores_y = pc_values[:, pc_y_idx_bi]

                fig_biplot.add_trace(
                    go.Scatter(
                        x=scores_x,
                        y=scores_y,
                        mode="markers",
                        name="Muestras (Scores)",
                        marker=dict(
                            size=10, color="#B0A461", line=dict(width=1, color="white")
                        ),
                        text=[f"Muestra {i}" for i in df_pca.index],
                        hovertemplate="<b>%{text}</b><br>%{x:.2f}, %{y:.2f}<extra></extra>",
                    )
                )

                # Add loadings (variables) as arrows
                loadings_x = pca.components_[pc_x_idx_bi, :]
                loadings_y = pca.components_[pc_y_idx_bi, :]

                # Scale loadings for visualization
                scale_factor = (
                    0.8
                    * max(np.max(np.abs(scores_x)), np.max(np.abs(scores_y)))
                    / max(np.max(np.abs(loadings_x)), np.max(np.abs(loadings_y)))
                )

                for i, var_name in enumerate(columns):
                    fig_biplot.add_trace(
                        go.Scatter(
                            x=[0, loadings_x[i] * scale_factor],
                            y=[0, loadings_y[i] * scale_factor],
                            mode="lines+markers+text",
                            name=var_name,
                            line=dict(color="#4A525A", width=2),
                            marker=dict(size=[0, 8], color="#4A525A"),
                            text=["", var_name],
                            textposition="top center",
                            textfont=dict(size=10, color="#4A525A"),
                            hovertemplate=f"<b>{var_name}</b><br>Loading X: {loadings_x[i]:.3f}<br>Loading Y: {loadings_y[i]:.3f}<extra></extra>",
                            showlegend=False,
                        )
                    )

                fig_biplot.update_layout(
                    title=f"Biplot: {pc_x_bi} vs {pc_y_bi}",
                    xaxis_title=f"{pc_x_bi} ({explained[pc_x_idx_bi] * 100:.2f}%)",
                    yaxis_title=f"{pc_y_bi} ({explained[pc_y_idx_bi] * 100:.2f}%)",
                    template="plotly_white",
                    hovermode="closest",
                    width=800,
                    height=600,
                )

                # Add origin lines
                fig_biplot.add_hline(
                    y=0, line_dash="dash", line_color="gray", opacity=0.5
                )
                fig_biplot.add_vline(
                    x=0, line_dash="dash", line_color="gray", opacity=0.5
                )

                st.plotly_chart(fig_biplot, use_container_width=True)

                st.markdown("### Interpretaci√≥n del Biplot")
                st.info("""
                **C√≥mo leer el biplot:**
                
                - **Puntos (Muestras):** Representan las observaciones proyectadas en el espacio de componentes principales
                - **Vectores (Variables):** Muestran la direcci√≥n y magnitud de la contribuci√≥n de cada variable
                - **√Ångulos entre vectores:**
                  - √Ångulo peque√±o (< 30¬∞): Variables positivamente correlacionadas
                  - √Ångulo cercano a 90¬∞: Variables no correlacionadas
                  - √Ångulo cercano a 180¬∞: Variables negativamente correlacionadas
                - **Longitud del vector:** Indica cu√°n bien est√° representada la variable en estas componentes
                - **Direcci√≥n muestra-variable:** Si una muestra est√° en la direcci√≥n de un vector, tiene valores altos en esa variable
                """)

        with tab4:
            st.subheader("Matriz de Loadings")
            st.markdown(
                "Los **loadings** muestran la contribuci√≥n de cada variable original a cada componente principal."
            )

            loadings_df = pd.DataFrame(
                pca.components_.T,
                columns=[f"PC{i + 1}" for i in range(n_components)],
                index=columns,
            )

            st.dataframe(
                loadings_df.style.background_gradient(cmap="RdYlGn", axis=None),
                use_container_width=True,
            )

            # Heatmap de loadings
            fig_heatmap = px.imshow(
                loadings_df.T,
                labels=dict(x="Variables", y="Componentes", color="Loading"),
                x=loadings_df.index,
                y=loadings_df.columns,
                color_continuous_scale="RdBu_r",
                aspect="auto",
            )
            fig_heatmap.update_layout(title="Heatmap de Loadings")
            st.plotly_chart(fig_heatmap, use_container_width=True)

        with tab4:
            st.subheader("Datos Transformados (Scores)")

            pc_df = pd.DataFrame(
                pc_values, columns=[f"PC{i + 1}" for i in range(n_components)]
            )

            st.dataframe(pc_df.head(20), use_container_width=True)

            csv = pc_df.to_csv(index=False)
            st.download_button(
                label="üì• Descargar datos PCA (CSV)",
                data=csv,
                file_name="pca_transformed.csv",
                mime="text/csv",
            )

        st.markdown("---")
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            if st.button(
                "‚û°Ô∏è Ir a Clustering",
                key="to_clustering",
                type="primary",
                use_container_width=True,
            ):
                st.session_state.page = "Clustering"
                st.session_state.pca_ready = False
                st.rerun()


# -------------------------------------------------
# CLUSTERING PAGE (ENHANCED)
# -------------------------------------------------
def cluster_page():
    st.header("üçá Clustering")

    with st.expander("‚ÑπÔ∏è ¬øQu√© es el Clustering?", expanded=False):
        st.markdown("""
        El **Clustering** es una t√©cnica de aprendizaje no supervisado que agrupa datos similares en "cl√∫steres" o grupos para identificar patrones y estructuras ocultas. 
        
        - üéØ Su objetivo es que los puntos de datos dentro de un mismo grupo sean m√°s parecidos entre s√≠ que con los de otros grupos, sin tener una etiqueta previa. 
        
        """)

    # Check dataset
    if "df" not in st.session_state or st.session_state.df is None:
        st.warning("‚ö†Ô∏è A√∫n no has cargado un dataset.")
        return

    df = st.session_state.df.copy()

    COLOR_PALETTES = {
        "QuimioAnalytics (Custom)": [
            "#B0A461",
            "#4A525A",
            "#E0D7B2",
            "#2E3339",
            "#8E9E9A",
        ],
        "Viridis (Default)": "viridis",
        "Plasma": "plasma",
        "Cividis": "cividis",
        "Inferno": "inferno",
        "Magma": "magma",
        "Cool Warm": ["#0000FF", "#87CEEB", "#FFFFFF", "#FF6347", "#FF0000"],
        "Greyscale": ["#000000", "#555555", "#AAAAAA", "#CCCCCC", "#FFFFFF"],
    }

    palette = COLOR_PALETTES.get(
        st.session_state.get("plot_color_choice", "QuimioAnalytics (Custom)")
    )

    st.markdown("---")

    # ================================================
    # üî¢ NUMERICAL COLUMNS
    # ================================================
    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if not numerical_cols:
        st.error("‚ùå No hay columnas num√©ricas para clustering.")
        return

    # ================================================
    # üéØ PCA Projection (Consistent with PCA Page)
    # ================================================
    st.subheader("üìâ Proyecci√≥n PCA para Visualizaci√≥n de Cl√∫steres")

    if st.session_state.get("pca_ready", False):
        try:
            # Use the PCA computed in pca_page
            columns = st.session_state.pca_columns
            X = df[columns].values
            pca = PCA(n_components=2)
            proj = pca.fit_transform(X)

            df["PC1"] = proj[:, 0]
            df["PC2"] = proj[:, 1]

            st.success("üéØ Usando PCA seleccionado en la p√°gina anterior.")
        except:
            st.error("El PCA previo no fue compatible. Se recalcular√°.")
            pca = PCA(n_components=2)
            proj = pca.fit_transform(df[numerical_cols])
            df["PC1"] = proj[:, 0]
            df["PC2"] = proj[:, 1]
    else:
        # Compute PCA from scratch for visualization
        pca = PCA(n_components=2)
        proj = pca.fit_transform(df[numerical_cols])
        df["PC1"] = proj[:, 0]
        df["PC2"] = proj[:, 1]

    # ================================================
    # üî∑ K-MEANS SECTION
    # ================================================
    with st.expander("üìå K-Means Clustering", expanded=True):
        k = st.slider("N√∫mero de clusters (k)", 2, 12, 3)
        n_init = st.slider("Repeticiones (n_init)", 5, 30, 10)
        init_method = st.selectbox("M√©todo de inicializaci√≥n", ["k-means++"])

        if st.button("üöÄ Ejecutar K-Means", type="primary", key="run_kmeans"):
            try:
                kmeans = KMeans(
                    n_clusters=k, n_init=n_init, init=init_method, random_state=42
                )
                labels = kmeans.fit_predict(df[numerical_cols])
                df["Cluster_KMeans"] = labels

                sil_score = silhouette_score(df[numerical_cols], labels)

                st.success(
                    f"‚úÖ K-Means completado. Silhouette Score: **{sil_score:.4f}**"
                )

                fig = px.scatter(
                    df,
                    x="PC1",
                    y="PC2",
                    color="Cluster_KMeans",
                    title="Cl√∫steres K-Means proyectados en espacio PCA",
                    opacity=0.85,
                    color_discrete_sequence=palette
                    if isinstance(palette, list)
                    else None,
                )
                st.plotly_chart(fig, use_container_width=True)

                st.subheader("üìä Resumen por Cl√∫ster")
                summary = df.groupby("Cluster_KMeans")[numerical_cols].mean()
                st.dataframe(summary, use_container_width=True)

            except Exception as e:
                st.error(f"‚ùå Error ejecutando K-Means: {e}")

    # ================================================
    # üåø HIERARCHICAL CLUSTERING
    # ================================================
    with st.expander("üåø Clustering Jer√°rquico"):
        linkage_method = st.selectbox(
            "M√©todo de enlace (linkage)", ["single", "complete", "average", "ward"]
        )

        num_clusters_h = st.slider("N√∫mero de clusters", 2, 12, 3, key="clusters_hier")

        if st.button("üå± Ejecutar Clustering Jer√°rquico", key="run_hier"):
            try:
                model = AgglomerativeClustering(
                    n_clusters=num_clusters_h,
                    linkage=linkage_method,
                    metric="euclidean",
                )
                df["Cluster_Hier"] = model.fit_predict(df[numerical_cols])

                st.success("‚úÖ Clustering jer√°rquico completado.")

                fig2 = px.scatter(
                    df,
                    x="PC1",
                    y="PC2",
                    color="Cluster_Hier",
                    title="Cl√∫steres Jer√°rquicos proyectados en espacio PCA",
                    opacity=0.85,
                    color_discrete_sequence=palette
                    if isinstance(palette, list)
                    else None,
                )
                st.plotly_chart(fig2, use_container_width=True)

                st.subheader("üìä Resumen por Cl√∫ster")
                st.dataframe(
                    df.groupby("Cluster_Hier")[numerical_cols].mean(),
                    use_container_width=True,
                )

                st.subheader("üå≥ Dendrograma")
                try:
                    linked = linkage(df[numerical_cols], method=linkage_method)
                    fig_d = ff.create_dendrogram(linked, orientation="left")
                    st.plotly_chart(fig_d, use_container_width=True)
                except Exception as dendro_error:
                    st.error(f"No se pudo generar el dendrograma: {dendro_error}")

            except Exception as e:
                st.error(f"‚ùå Error ejecutando clustering jer√°rquico: {e}")

    # ================================================
    # NAVIGATION
    # ================================================
    st.markdown("---")
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        if st.button("‚û°Ô∏è Ir a ANOVA", type="primary"):
            st.session_state.page = "ANOVA"
            st.rerun()


# -------------------------------------------------
# ANOVA PAGE (ENHANCED)
# -------------------------------------------------
def anova_page():
    st.header("üßÆ An√°lisis de Varianza (ANOVA)")

    # Initialize flag
    if "anova_done" not in st.session_state:
        st.session_state.anova_done = False

    with st.expander("‚ÑπÔ∏è ¬øQu√© es el ANOVA?", expanded=False):
        st.markdown("""
        El **ANOVA** ...
        """)

    COLOR_PALETTES = {
        "QuimioAnalytics (Custom)": [
            "#B0A461",
            "#4A525A",
            "#E0D7B2",
            "#2E3339",
            "#8E9E9A",
        ],
        "Viridis (Default)": "viridis",
        "Plasma": "plasma",
        "Cool Warm": ["#0000FF", "#87CEEB", "#FFFFFF", "#FF6347", "#FF0000"],
        "Greyscale": ["#000000", "#555555", "#AAAAAA", "#CCCCCC", "#FFFFFF"],
    }

    if st.session_state.df is None:
        st.warning("‚ö†Ô∏è Carga un dataset primero.")
        return

    df_anova = st.session_state.df.copy()

    if "plot_color_choice" not in st.session_state:
        st.session_state.plot_color_choice = "QuimioAnalytics (Custom)"

    numerical_cols = df_anova.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df_anova.select_dtypes(
        include=["object", "category"]
    ).columns.tolist()

    if not numerical_cols or not categorical_cols:
        st.error(
            "‚ùå Se necesita al menos una columna num√©rica y una categ√≥rica para ANOVA."
        )
        return

    col1, col2, col3 = st.columns([2, 2, 1])

    with col1:
        y_var = st.selectbox(
            "üéØ Variable Dependiente (Num√©rica):", numerical_cols, key="anova_y"
        )

    with col2:
        x_var = st.selectbox(
            "üè∑Ô∏è Variable Factor/Grupo (Categ√≥rica):", categorical_cols, key="anova_x"
        )

    with col3:
        st.session_state.plot_color_choice = st.selectbox(
            "üé® Paleta:",
            list(COLOR_PALETTES.keys()),
            index=list(COLOR_PALETTES.keys()).index(st.session_state.plot_color_choice),
        )

    st.markdown("---")

    # --------------------------------------------------
    # ‚ñ∂Ô∏è APPLY ANOVA (kept exactly as you had it)
    # --------------------------------------------------

    if st.button("‚ñ∂Ô∏è Aplicar ANOVA", type="primary"):
        df_model = df_anova[[y_var, x_var]].copy()
        df_model = df_model.dropna()

        df_model[x_var] = df_model[x_var].astype("category")

        if df_model.shape[0] < 3:
            st.error("‚ùå No hay suficientes datos para realizar ANOVA.")
            return

        n_groups = df_model[x_var].nunique()
        if n_groups < 2:
            st.error(
                f"‚ùå Se necesitan al menos 2 grupos diferentes. Solo se encontr√≥ {n_groups} grupo."
            )
            return

        formula = f'Q("{y_var}") ~ C(Q("{x_var}"))'

        try:
            model = ols(formula, data=df_model).fit()
            anova_table = sm.stats.anova_lm(model, typ=2)

            st.success("‚úÖ ANOVA completado")

            # Store values so the button can work later
            st.session_state.anova_done = True
            st.session_state.anova_table = anova_table
            st.session_state.df_model = df_model
            st.session_state.y_var = y_var
            st.session_state.x_var = x_var

        except Exception as e:
            st.error(f"‚ùå Error al calcular ANOVA: {e}")
            return

    # --------------------------------------------------
    # SHOW THE AI CHAT BUTTON ONLY IF ANOVA WAS RUN
    # --------------------------------------------------

    if st.session_state.anova_done:
        st.markdown("---")
        colA, colB, colC = st.columns([1, 1, 1])
        with colB:
            if st.button(
                "‚û°Ô∏è Ir con Heisenberg", type="primary", use_container_width=True
            ):
                st.session_state.page = "AI Chat"
                st.rerun()

        # --------------------------------------------------
        # Now show all tabs normally (your original code)
        # --------------------------------------------------
        anova_table = st.session_state.anova_table
        df_model = st.session_state.df_model
        y_var = st.session_state.y_var
        x_var = st.session_state.x_var

        tab1, tab2, tab3, tab4 = st.tabs(
            [
                "üìä Tabla ANOVA",
                "üìà Visualizaciones",
                "üîç Test Post-Hoc",
                "üìã Estad√≠sticas Descriptivas",
            ]
        )


# -------------------------
# PAGE: AI CHAT
# -------------------------
def ai_chat_page():
    st.header("üí¨ Chat de I.A.")

    # Check dataset
    if st.session_state.df is None:
        st.warning("‚ö†Ô∏è Carga un dataset primero.")
        return

    df = st.session_state.df

    # Load image safely
    img_path = pathlib.Path("man.png")
    img_data_uri = None

    try:
        with img_path.open("rb") as f:
            data = f.read()
            b64 = base64.b64encode(data).decode("utf-8")
            img_data_uri = f"data:image/png;base64,{b64}"
    except Exception as e:
        st.warning(f"No se pudo cargar man.png ({e}).")

    # ----------- CSS (fixed version) ----------
    st.markdown(
        f"""
        <style>
        .floating-image-container {{
            position: fixed;
            top: 500px;
            right: 25px;
            width: 80px;
            z-index: 9999;
            text-align: center;
        }}
        
        .floating-image-container img {{
            width: 100%;
            height: auto;
            border-radius: 0px;
            box-shadow: 0 0px 0px rgba(0,0,0,0);
            display: block;
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )

    # ----------- Insert floating image (fixed) -----------
    if img_data_uri:
        st.markdown(
            f"""
            <div class="floating-image-container">
                <img src="{img_data_uri}">
            </div>
            """,
            unsafe_allow_html=True,
        )
    else:
        # fallback
        st.image("man.png", width=150)

    # -------------------------
    # Initialize session state
    # -------------------------
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    if "clear_input" not in st.session_state:
        st.session_state.clear_input = False

    # --- The input processing logic needs to stay at the top for the rerun to work correctly. ---

    # Process submitted message from the form that will be defined later
    if st.session_state.get("submitted_input"):
        user_input = st.session_state.submitted_input
        # Remove the flag and value immediately after retrieving them
        del st.session_state.submitted_input

        if user_input.strip():
            st.session_state.chat_history.append(
                {"role": "user", "content": user_input}
            )
            st.session_state.last_user_input = user_input
            # st.session_state.clear_input = True # No longer needed with the new st.chat_input pattern
            st.rerun()
        # else:
        # st.warning("‚ö†Ô∏è Please enter a message before sending.") # Use st.chat_input, which handles empty messages

    # -------------------------
    # Render chat history
    # -------------------------
    # Use st.container() to hold the chat history
    chat_box_container = st.container()

    with chat_box_container:
        # Loop through and display messages
        for msg in st.session_state.chat_history:
            if msg["role"] == "user":
                with st.chat_message("user"):
                    st.write(msg["content"])
            else:
                with st.chat_message("assistant"):
                    st.write(msg["content"])

        # Placeholder for streaming text. It must be created *before* the input logic for correct placement.
        streaming_placeholder = st.empty()

    # -------------------------
    # Build dataset description for the AI (kept in place)
    # -------------------------
    dataset_description = f"""
You have access to the user's uploaded dataset.

COLUMN NAMES:
{", ".join(df.columns)}

DATA TYPES:
{df.dtypes.to_string()}

SUMMARY STATISTICS:
{df.describe().to_string()}

FIRST 10 ROWS:
{df.head(10).to_string(index=False)}
"""

    # -------------------------
    # Process LLM response (kept in place)
    # -------------------------
    if "last_user_input" in st.session_state:
        user_msg = st.session_state.pop("last_user_input")

        messages_for_api = [
            {
                "role": "system",
                "content": (
                    "You are an expert data analyst specializing in statistics, chemistry, "
                    "machine learning and dataset interpretation.\n"
                    "Use the dataset description below to answer questions accurately, "
                    "identify patterns, recommend preprocessing steps, "
                    "and generate insights.\n\n"
                    f"{dataset_description}"
                ),
            },
            # Append historical chat messages
            *[
                msg
                for msg in st.session_state.chat_history
                if msg["content"]
                != dataset_description  # Avoid including the system prompt description in the history sent to the model repeatedly
            ],
        ]

        try:
            # client.chat.completions.create is assumed to be available
            stream = client.chat.completions.create(
                model="llama-3.1-8b-instant",
                messages=messages_for_api,
                stream=True,
            )

            full_response = ""

            # Streaming response inside the placeholder
            with streaming_placeholder.container():
                text_placeholder = st.empty()

                for chunk in stream:
                    content = chunk.choices[0].delta.content
                    if content:
                        full_response += content
                        text_placeholder.markdown(
                            f"<div style='text-align:left;'>**AI:** {full_response}‚ñå</div>",
                            unsafe_allow_html=True,
                        )

                # Final update
                text_placeholder.markdown(
                    f"<div style='text-align:left;'>**AI:** {full_response}</div>",
                    unsafe_allow_html=True,
                )

                if full_response:
                    st.session_state.chat_history.append(
                        {"role": "assistant", "content": full_response}
                    )

            st.rerun()

        except NameError:
            # Handle case where 'client' is not defined in this snippet (simulating error handling)
            st.error("Groq API client not found (assuming external dependency).")
        except Exception as e:
            st.error(f"API Error: {e}")
            # Remove the last user message if the API call failed
            if (
                st.session_state.chat_history
                and st.session_state.chat_history[-1]["role"] == "user"
            ):
                st.session_state.chat_history.pop()

    user_input = st.chat_input(
        "Pregunta algo sobre el dataset cargado", key="chat_input_box"
    )

    # st.chat_input returns the user's message when submitted.
    if user_input:
        # Save the input to a session state variable to process it at the top of the script
        st.session_state.submitted_input = user_input
        st.rerun()


# -------------------------------------------------
# SIDEBAR NAVIGATION
# -------------------------------------------------
with st.sidebar:
    st.markdown("### üß™ QuimioAnalytics")
    st.markdown("---")

    if st.button("üè† Home", use_container_width=True):
        st.session_state.page = "Home"

    if st.button("üìÇ Cargar Dataset", use_container_width=True):
        st.session_state.page = "Cargar dataset"

    if st.button("üîß Preprocesamiento", use_container_width=True):
        st.session_state.page = "Preprocesamiento de Datos"

    if st.button("üìà An√°lisis PCA", use_container_width=True):
        st.session_state.page = "PCA"

    if st.button("üçá Clustering", use_container_width=True):
        st.session_state.page = "Clustering"

    if st.button("üßÆ ANOVA", use_container_width=True):
        st.session_state.page = "ANOVA"

    if st.button("üí¨ AI Chat", use_container_width=True):
        st.session_state.page = "AI Chat"

    st.markdown("---")
    st.markdown("##### üìä Estado del Dataset")
    if st.session_state.df is not None:
        st.success("‚úÖ Dataset cargado")
        st.info(f"üìã {st.session_state.df.shape[0]} filas")
        st.info(f"üìä {st.session_state.df.shape[1]} columnas")
        if st.session_state.get("standardized"):
            st.success("‚úÖ Estandarizado")
    else:
        st.warning("‚ö†Ô∏è Sin dataset")

# -------------------------------------------------
# PAGE CONTROLLER
# -------------------------------------------------
if st.session_state.page == "Home":
    home_page()

elif st.session_state.page == "Cargar dataset":
    cargar_dataset()

elif st.session_state.page == "Preprocesamiento de Datos":
    preprocessing_page()

elif st.session_state.page == "PCA":
    pca_page()

elif st.session_state.page == "Clustering":
    cluster_page()

elif st.session_state.page == "ANOVA":
    anova_page()

elif st.session_state.page == "AI Chat":
    ai_chat_page()
